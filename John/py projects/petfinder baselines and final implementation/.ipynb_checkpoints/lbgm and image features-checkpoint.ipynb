{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n",
    "#Reference: https://www.kaggle.com/kgeorge/yolo-v3-object-detection-for-petfinder/\n",
    "\n",
    "import json\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import lightgbm as lgb\n",
    "np.random.seed(369)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "def rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "0008c5398-1    0008c5398\n",
       "000a290e4-1    000a290e4\n",
       "000fb9572-1    000fb9572\n",
       "0011d7c25-1    0011d7c25\n",
       "00156db4a-1    00156db4a\n",
       "001a1aaad-1    001a1aaad\n",
       "001b1507c-1    001b1507c\n",
       "002230dea-1    002230dea\n",
       "002278114-1    002278114\n",
       "0025a8313-1    0025a8313\n",
       "0038234c6-1    0038234c6\n",
       "0038c9343-1    0038c9343\n",
       "003dd2e26-1    003dd2e26\n",
       "0045ed62a-1    0045ed62a\n",
       "004709939-1    004709939\n",
       "004a26127-1    004a26127\n",
       "004c2f355-1    004c2f355\n",
       "0052dcf47-1    0052dcf47\n",
       "00553ae55-1    00553ae55\n",
       "0058586f1-1    0058586f1\n",
       "005afe792-1    005afe792\n",
       "005bb92d8-1    005bb92d8\n",
       "0063bd7e0-1    0063bd7e0\n",
       "0063f83c9-1    0063f83c9\n",
       "00648f96f-1    00648f96f\n",
       "006610fe3-1    006610fe3\n",
       "006d301e9-1    006d301e9\n",
       "006ffebaf-1    006ffebaf\n",
       "00709d75b-1    00709d75b\n",
       "0073c33d0-1    0073c33d0\n",
       "                 ...    \n",
       "ff8e7c016-1    ff8e7c016\n",
       "ff96988fc-1    ff96988fc\n",
       "ff9ce365b-1    ff9ce365b\n",
       "ff9d8cb25-1    ff9d8cb25\n",
       "ff9f62e79-1    ff9f62e79\n",
       "ffa5c6c35-1    ffa5c6c35\n",
       "ffaa73202-1    ffaa73202\n",
       "ffab93d18-1    ffab93d18\n",
       "ffb315803-1    ffb315803\n",
       "ffb33c204-1    ffb33c204\n",
       "ffb3a78e1-1    ffb3a78e1\n",
       "ffb6a7f5d-1    ffb6a7f5d\n",
       "ffbc3eaaf-1    ffbc3eaaf\n",
       "ffd2e82a9-1    ffd2e82a9\n",
       "ffd506899-1    ffd506899\n",
       "ffd61a488-1    ffd61a488\n",
       "ffd697903-1    ffd697903\n",
       "ffdad97e5-1    ffdad97e5\n",
       "ffe0f06ab-1    ffe0f06ab\n",
       "ffe2090b3-1    ffe2090b3\n",
       "ffe5a0271-1    ffe5a0271\n",
       "ffe7f0b70-1    ffe7f0b70\n",
       "ffebad2e7-1    ffebad2e7\n",
       "ffef9a2af-1    ffef9a2af\n",
       "fff24fcb5-1    fff24fcb5\n",
       "fff4a6420-1    fff4a6420\n",
       "fff6f2f61-1    fff6f2f61\n",
       "fffa39a6a-1    fffa39a6a\n",
       "fffd78a11-1    fffd78a11\n",
       "fffd9b5a8-1    fffd9b5a8\n",
       "Name: name, Length: 14652, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "import tensorflow as tf\n",
    "\n",
    "train_df = pd.read_csv('input/train/train.csv')\n",
    "img_size = 256\n",
    "batch_size = 16\n",
    "\n",
    "train_detect = pd.read_csv('input/train/train_detections.csv')\n",
    "\n",
    "train_detect = train_detect.set_index(\"name\", drop = False)\n",
    "print(train_detect.loc[\"0008c5398-1\", \"x1\"])\n",
    "\n",
    "train_detect.loc[:, 'name'].replace(regex=True, to_replace=\"-1\", value=\"\")\n",
    "\n",
    "#pet_ids = train_detect['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop1(path, graypath, graypathcropped, valid_types):\n",
    "    import sys, os\n",
    "    i = 0\n",
    "    img_preview = -1\n",
    "    for f in tqdm_notebook(os.listdir(path), desc='cropping progress'):\n",
    "        i += 1\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        \n",
    "        if ext.lower() not in valid_types:\n",
    "            return\n",
    "        \n",
    "        n = f.split(\"-\")[0]\n",
    "        #print(n)\n",
    "        if not os.path.isfile(graypath + n + \"/\" + f):\n",
    "            image = cv2.imread(path+\"/\"+f) #pass in 0 as second parameter to automatically convert to grayscale\n",
    "            cropped = image\n",
    "            \n",
    "            if image is not None:\n",
    "                #try:\n",
    "                    x1 = train_detect.loc[ n + \"-1\", \"x1\" ]\n",
    "                    x2 = train_detect.loc[ n + \"-1\", \"x2\" ]\n",
    "                    y1 = train_detect.loc[ n + \"-1\", \"y1\" ]\n",
    "                    y2 = train_detect.loc[ n + \"-1\", \"y2\" ]\n",
    "                    #print(y1, y2, x1,x2)\n",
    "                    cropped = image[y1:y2, x1:x2]\n",
    "                \n",
    "                    if i <= img_preview:\n",
    "                        cv2.imshow('cropped_image',cropped) \n",
    "                        cv2.waitKey(0)                 # Waits forever for user to press any key\n",
    "                        cv2.destroyAllWindows()        # Closes displayed windows\n",
    "\n",
    "                    if not os.path.isfile(graypath + \"/\" + f):\n",
    "                        cv2.imwrite(graypath + \"/\" + f, cropped)\n",
    "                        #print(\"\\rCreated File: \" + graypath + \"/\" + f, end='')\n",
    "                #except:\n",
    "                 #   pass\n",
    "    return\n",
    "\n",
    "def crop2(path, graypath, graypathcropped, valid_types):\n",
    "    import sys, os\n",
    "    i = 0\n",
    "    img_preview = -1\n",
    "    for f in tqdm_notebook(os.listdir(path), desc='grayscale cropping progress'):\n",
    "        i += 1\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        \n",
    "        if ext.lower() not in valid_types:\n",
    "            return\n",
    "        \n",
    "        n = f.split(\"-\")[0]\n",
    "        \n",
    "        if not os.path.isfile(graypathcropped + n + \"/\" + f):\n",
    "            image = cv2.imread(path+\"/\"+f, 0) #pass in 0 as second parameter to automatically convert to grayscale\n",
    "            cropped = image\n",
    "            \n",
    "            if image is not None:\n",
    "                try:\n",
    "                    x1 = train_detect.loc[n + \"-1\", \"x1\"]\n",
    "                    x2 = train_detect.loc[n + \"-1\", \"x2\"]\n",
    "                    y1 = train_detect.loc[n + \"-1\", \"y1\"]\n",
    "                    y2 = train_detect.loc[n + \"-1\", \"y2\"]\n",
    "                    \n",
    "                    cropped = image[y1:y2, x1:x2]\n",
    "                \n",
    "                    if i <= img_preview:\n",
    "                        cv2.imshow('cropped_image',cropped) \n",
    "                        cv2.waitKey(0)                 # Waits forever for user to press any key\n",
    "                        cv2.destroyAllWindows()        # Closes displayed windows\n",
    "\n",
    "                    if not os.path.isfile(graypathcropped + \"/\" + f):\n",
    "                        cv2.imwrite(graypathcropped + \"/\" + f, cropped)\n",
    "                        #print(\"\\rCreated File: \" + graypathcropped + \"/\" + f, end='')\n",
    "                except:\n",
    "                    pass\n",
    "    return\n",
    "\n",
    "def crop():\n",
    "    import sys, os\n",
    "    \n",
    "    path = \"input/train/train_images/\"\n",
    "    graypath = \"input/train/cropped_images/\"\n",
    "    graypathcropped = \"input/train/grayscale_cropped_images/\"\n",
    "    \n",
    "    if not os.path.exists(\"input\"):\n",
    "        os.mkdir(\"input\")\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    if not os.path.exists(graypath):\n",
    "        os.mkdir(graypath)\n",
    "    if not os.path.exists(graypathcropped):\n",
    "        os.mkdir(graypathcropped)\n",
    "    \n",
    "    valid_types = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "    #for f in tqdm_notebook(os.listdir(path), desc='Directory Labelling Progress'):\n",
    "    #    ext = os.path.splitext(f)[1]\n",
    "    #    if ext.lower() not in valid_types:\n",
    "    #        return\n",
    "    #    n = f.split(\"-\")[0]\n",
    "    #    if not os.path.exists(graypath + n + \"/\"):\n",
    "    #        os.mkdir(graypath + n + \"/\")\n",
    "    #        print(\"\\rCreated Directory: \" + graypath + n + \"/\", end='')\n",
    "    useTF = False\n",
    "    if useTF:\n",
    "        import tensorflow as tf\n",
    "        from keras import backend as K\n",
    "\n",
    "        #https://regressionsessionsblog.wordpress.com/2018/06/11/stuck-on-an-issue-making-keras-predictions-in-parallel/\n",
    "        #https://github.com/keras-team/keras/issues/4740\n",
    "        jobs = 6\n",
    "        config = tf.ConfigProto(intra_op_parallelism_threads=jobs, \\\n",
    "                            inter_op_parallelism_threads=jobs, \\\n",
    "                            allow_soft_placement=True, \\\n",
    "                            device_count = {'CPU': jobs})\n",
    "        sess = tf.Session(config=config)\n",
    "        K.set_session(sess)\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.no_op())\n",
    "            crop1(path, graypath, graypathcropped, valid_types)\n",
    "            crop2(path, graypath, graypathcropped, valid_types)\n",
    "            sess.close()\n",
    "    else:\n",
    "        crop1(path, graypath, graypathcropped, valid_types)\n",
    "        crop2(path, graypath, graypathcropped, valid_types)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip cropping\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"skip cropping\")\n",
    "#crop()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = train_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # new_size should be in (width, height) format\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "def train_keras():\n",
    "    from keras.models import Model\n",
    "    from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #https://regressionsessionsblog.wordpress.com/2018/06/11/stuck-on-an-issue-making-keras-predictions-in-parallel/\n",
    "    #https://github.com/keras-team/keras/issues/4740\n",
    "    jobs = 6\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=jobs, \\\n",
    "                            inter_op_parallelism_threads=jobs, \\\n",
    "                            allow_soft_placement=True, \\\n",
    "                            device_count = {'CPU': jobs})\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "\n",
    "    print(\"start\")\n",
    "    inp = Input((img_size,img_size,3))\n",
    "    backbone = DenseNet121(input_tensor = inp, \n",
    "                            weights=\"input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n",
    "                            include_top = False)\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "    x = AveragePooling1D(4)(x)\n",
    "    out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "    m = Model(inp,out)\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"start keras prediction\")\n",
    "\n",
    "    for b in tqdm_notebook(range(n_batches)):\n",
    "        start = b*batch_size\n",
    "        end = (b+1)*batch_size\n",
    "        batch_pets = pet_ids[start:end]\n",
    "        batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            try:\n",
    "                batch_images[i] = load_image(\"input/train/cropped_images/\", pet_id)\n",
    "            except:\n",
    "                pass\n",
    "        batch_preds = m.predict(batch_images)\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            features[pet_id] = batch_preds[i]\n",
    "    print(\"done keras prediction\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "done\n",
      "start keras prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226e58072df041eaae019896c9d933bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=921), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done keras prediction\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "#m = train_keras(\"input/train/cropped_images/\")\n",
    "m = train_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train features json to disk\n"
     ]
    }
   ],
   "source": [
    "def save_json(features, filename=\"train_features\"):\n",
    "    with open(filename + \".json\", 'w') as file:\n",
    "        json.dump(features,file)\n",
    "        #json.dump(dictionary, file, sort_keys=True, indent=4)\n",
    "    return\n",
    "def load_json(filename=\"file\", dictionary=features):\n",
    "    with open(filename + \".json\", 'r') as file:\n",
    "        loaded_file = json.load(file)\n",
    "    return loaded_file\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)): #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "dumped = json.dumps(features, cls=NumpyEncoder)\n",
    "\n",
    "with open(\"train_features.json\", 'w') as f:\n",
    "    json.dump(dumped, f)\n",
    "    print(\"Saved train features json to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model weights to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(m.summary())\n",
    "\n",
    "m.save_weights(\"keras_model_weights.h5\")\n",
    "print(\"Saved model weights to disk\")\n",
    "#with open(\"train_features.json\", 'r') as f:\n",
    "#    train_loaded_features = json.load(f)\n",
    "#    train_loaded_features = json.loads(train_loaded_features)\n",
    "#    print(\"loaded train features\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start create model\n",
      "done\n",
      "start keras test prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5c1cab876045b99af5bf4eaba4466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done keras test prediction\n",
      "Saved test features json to disk\n"
     ]
    }
   ],
   "source": [
    "train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "train_feats.columns = ['pic_'+str(i) for i in range(train_feats.shape[1])]\n",
    "test_df = pd.read_csv('input/test/test.csv')\n",
    "\n",
    "pet_ids = test_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "test_features = {}\n",
    "\n",
    "def train_test_keras(m, n_batches):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #https://regressionsessionsblog.wordpress.com/2018/06/11/stuck-on-an-issue-making-keras-predictions-in-parallel/\n",
    "    #https://github.com/keras-team/keras/issues/4740\n",
    "    jobs = 6\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=jobs, \\\n",
    "                            inter_op_parallelism_threads=jobs, \\\n",
    "                            allow_soft_placement=True, \\\n",
    "                            device_count = {'CPU': jobs})\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "\n",
    "    print(\"start create model\")\n",
    "    inp = Input((img_size,img_size,3))\n",
    "    backbone = DenseNet121(input_tensor = inp, \n",
    "                            weights=\"input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n",
    "                            include_top = False)\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "    x = AveragePooling1D(4)(x)\n",
    "    out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "    m = Model(inp,out)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"start keras test prediction\")\n",
    "\n",
    "    for b in tqdm_notebook(range(n_batches)):\n",
    "        start = b*batch_size\n",
    "        end = (b+1)*batch_size\n",
    "        batch_pets = pet_ids[start:end]\n",
    "        batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            try:\n",
    "                batch_images[i] = load_image(\"input/test/test_images/\", pet_id)\n",
    "            except:\n",
    "                pass\n",
    "        batch_preds = m.predict(batch_images)\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            test_features[pet_id] = batch_preds[i]\n",
    "    print(\"done keras test prediction\")\n",
    "    return\n",
    "\n",
    "train_test_keras(m, n_batches)\n",
    "\n",
    "dumped = json.dumps(test_features, cls=NumpyEncoder)\n",
    "\n",
    "with open(\"test_features.json\", 'w') as f:\n",
    "    json.dump(dumped, f)\n",
    "    print(\"Saved test features json to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved image test features prediction values to CSV\n"
     ]
    }
   ],
   "source": [
    "test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "test_feats.columns = ['pic_'+str(i) for i in range(test_feats.shape[1])]\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "test_feats.head()\n",
    "\n",
    "test_feats.to_csv(r'csv_out/img_test_feats_prediction_values.csv')\n",
    "print(\"saved image test features prediction values to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Here after image prediction files have been made ### \n",
    "\n",
    "this uses train and test.csv files along with the test_features and train_features json files, from which you will be able to run the remainder of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train features\n",
      "loaded test features\n",
      "creating dataframes from feature dictionaries\n",
      "joining dataframes\n",
      "saved train csv image merge\n",
      "saved test csv image merge\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train/train.csv\")\n",
    "test = pd.read_csv(\"input/test/test.csv\")\n",
    "\n",
    "target = train['AdoptionSpeed']\n",
    "train_id = train['PetID']\n",
    "test_id = test['PetID']\n",
    "\n",
    "loaded_train_feats = {}\n",
    "loaded_test_feats = {}\n",
    "with open(\"train_features.json\", 'r') as f:\n",
    "    loaded_train_feats = json.load(f)\n",
    "    loaded_train_feats = json.loads(loaded_train_feats)\n",
    "    print(\"loaded train features\")\n",
    "\n",
    "with open(\"test_features.json\", 'r') as f:\n",
    "    loaded_test_feats = json.load(f)\n",
    "    loaded_test_feats = json.loads(loaded_test_feats)\n",
    "    print(\"loaded test features\") \n",
    "\n",
    "print(\"creating dataframes from feature dictionaries\")\n",
    "train_feats = pd.DataFrame.from_dict(loaded_train_feats, orient='index')\n",
    "train_feats.columns = ['pic_'+str(i) for i in range(train_feats.shape[1])]\n",
    "\n",
    "test_feats = pd.DataFrame.from_dict(loaded_test_feats, orient='index')\n",
    "test_feats.columns = ['pic_'+str(i) for i in range(test_feats.shape[1])]\n",
    "\n",
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "print(\"joining dataframes\")\n",
    "train = train.join(train_feats.set_index('PetID'),on='PetID')\n",
    "test = test.join(test_feats.set_index('PetID'),on='PetID')\n",
    "#train = pd.merge(train, train_feats, on = ['PetID'], how = 'left')\n",
    "#test = pd.merge(test, test_feats, left_on = ['PetID'], right_on = ['PetID'], how = 'outer')\n",
    "\n",
    "train.drop(['AdoptionSpeed', 'PetID'], axis=1, inplace=True)\n",
    "test.drop(['PetID'], axis=1, inplace=True)\n",
    "\n",
    "#prepared = train\n",
    "#prepared.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "\n",
    "#train.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "#test.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "\n",
    "#prepared.to_csv(r'csv_out/cleaned_img_merge.csv')\n",
    "#print(\"saved prepared csv\")\n",
    "train.to_csv(r'csv_out/train_csv_img_merge.csv')\n",
    "print(\"saved train csv image merge\")\n",
    "test.to_csv(r'csv_out/test_csv_img_merge.csv')\n",
    "print(\"saved test csv image merge\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sentiment train\n",
      "loading sentiment test\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "doc_sent_mag = []\n",
    "doc_sent_score = []\n",
    "nf_count = 0\n",
    "print(\"loading sentiment train\")\n",
    "for petid in train_id:\n",
    "    try:\n",
    "        with open('input/train/train_sentiment/' + petid + '.json', 'r') as f:\n",
    "            sentiment = json.load(f)\n",
    "        doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n",
    "        doc_sent_score.append(sentiment['documentSentiment']['score'])\n",
    "    except  Exception:\n",
    "        nf_count += 1\n",
    "        doc_sent_mag.append(-1)\n",
    "        doc_sent_score.append(-1)\n",
    "        pass\n",
    "\n",
    "train.loc[:, 'doc_sent_mag'] = doc_sent_mag\n",
    "train.loc[:, 'doc_sent_score'] = doc_sent_score\n",
    "\n",
    "doc_sent_mag = []\n",
    "doc_sent_score = []\n",
    "nf_count = 0\n",
    "print(\"loading sentiment test\")\n",
    "for petid in test_id:\n",
    "    try:\n",
    "        with open('input/test/test_sentiment/' + petid + '.json', 'r') as f:\n",
    "            sentiment = json.load(f)\n",
    "        doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n",
    "        doc_sent_score.append(sentiment['documentSentiment']['score'])\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        doc_sent_mag.append(-1)\n",
    "        doc_sent_score.append(-1)\n",
    "        pass\n",
    "\n",
    "test.loc[:, 'doc_sent_mag'] = doc_sent_mag\n",
    "test.loc[:, 'doc_sent_score'] = doc_sent_score\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit training sentiment descriptions\n",
      "X (tfidf): (14720, 10000)\n",
      "X (svd): (14720, 200)\n",
      "train: (14720, 480)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"scikit training sentiment descriptions\")\n",
    "## WITHOUT ERROR FIXED\n",
    "train_desc = train.Description.fillna(\"none\").values\n",
    "test_desc = test.Description.fillna(\"none\").values\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=10000,\n",
    "        strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "    \n",
    "# Fit TFIDF\n",
    "tfv.fit(list(train_desc))\n",
    "X =  tfv.transform(train_desc)\n",
    "X_test = tfv.transform(test_desc)\n",
    "print(\"X (tfidf):\", X.shape)\n",
    "\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "svd.fit(X)\n",
    "# print(svd.explained_variance_ratio_.sum())\n",
    "# print(svd.explained_variance_ratio_)\n",
    "X = svd.transform(X)\n",
    "print(\"X (svd):\", X.shape)\n",
    "\n",
    "X = pd.DataFrame(X, columns=['svd_{}'.format(i) for i in range(200)])\n",
    "train = pd.concat((train, X), axis=1)\n",
    "X_test = svd.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=['svd_{}'.format(i) for i in range(200)])\n",
    "test = pd.concat((test, X_test), axis=1)\n",
    "\n",
    "print(\"train:\", train.shape)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading metadata train\n",
      "363\n",
      "2\n",
      "loading metadata test\n",
      "137\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "vertex_xs = []\n",
    "vertex_ys = []\n",
    "bounding_confidences = []\n",
    "bounding_importance_fracs = []\n",
    "dominant_blues = []\n",
    "dominant_greens = []\n",
    "dominant_reds = []\n",
    "dominant_pixel_fracs = []\n",
    "dominant_scores = []\n",
    "label_descriptions = []\n",
    "label_scores = []\n",
    "nf_count = 0\n",
    "nl_count = 0\n",
    "print(\"loading metadata train\")\n",
    "for petid in train_id:\n",
    "    try:\n",
    "        with open('input/train/train_metadata/' + petid + '-1.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n",
    "            vertex_xs.append(vertex_x)\n",
    "            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n",
    "            vertex_ys.append(vertex_y)\n",
    "            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n",
    "            bounding_confidences.append(bounding_confidence)\n",
    "            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n",
    "            bounding_importance_fracs.append(bounding_importance_frac)\n",
    "            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n",
    "            dominant_blues.append(dominant_blue)\n",
    "            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n",
    "            dominant_greens.append(dominant_green)\n",
    "            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n",
    "            dominant_reds.append(dominant_red)\n",
    "            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n",
    "            dominant_pixel_fracs.append(dominant_pixel_frac)\n",
    "            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n",
    "            dominant_scores.append(dominant_score)\n",
    "            if data.get('labelAnnotations'):\n",
    "                label_description = data['labelAnnotations'][0]['description']\n",
    "                label_descriptions.append(label_description)\n",
    "                label_score = data['labelAnnotations'][0]['score']\n",
    "                label_scores.append(label_score)\n",
    "            else:\n",
    "                nl_count += 1\n",
    "                label_descriptions.append('nothing')\n",
    "                label_scores.append(-1)\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        vertex_xs.append(-1)\n",
    "        vertex_ys.append(-1)\n",
    "        bounding_confidences.append(-1)\n",
    "        bounding_importance_fracs.append(-1)\n",
    "        dominant_blues.append(-1)\n",
    "        dominant_greens.append(-1)\n",
    "        dominant_reds.append(-1)\n",
    "        dominant_pixel_fracs.append(-1)\n",
    "        dominant_scores.append(-1)\n",
    "        label_descriptions.append('nothing')\n",
    "        label_scores.append(-1)\n",
    "        pass\n",
    "\n",
    "print(nf_count)\n",
    "print(nl_count)\n",
    "train.loc[:, 'vertex_x'] = vertex_xs\n",
    "train.loc[:, 'vertex_y'] = vertex_ys\n",
    "train.loc[:, 'bounding_confidence'] = bounding_confidences\n",
    "train.loc[:, 'bounding_importance'] = bounding_importance_fracs\n",
    "train.loc[:, 'dominant_blue'] = dominant_blues\n",
    "train.loc[:, 'dominant_green'] = dominant_greens\n",
    "train.loc[:, 'dominant_red'] = dominant_reds\n",
    "train.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n",
    "train.loc[:, 'dominant_score'] = dominant_scores\n",
    "train.loc[:, 'label_description'] = label_descriptions\n",
    "train.loc[:, 'label_score'] = label_scores\n",
    "\n",
    "\n",
    "vertex_xs = []\n",
    "vertex_ys = []\n",
    "bounding_confidences = []\n",
    "bounding_importance_fracs = []\n",
    "dominant_blues = []\n",
    "dominant_greens = []\n",
    "dominant_reds = []\n",
    "dominant_pixel_fracs = []\n",
    "dominant_scores = []\n",
    "label_descriptions = []\n",
    "label_scores = []\n",
    "nf_count = 0\n",
    "nl_count = 0\n",
    "print(\"loading metadata test\")\n",
    "for petid in test_id:\n",
    "    try:\n",
    "        with open('input/test/test_metadata/' + petid + '-1.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n",
    "            vertex_xs.append(vertex_x)\n",
    "            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n",
    "            vertex_ys.append(vertex_y)\n",
    "            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n",
    "            bounding_confidences.append(bounding_confidence)\n",
    "            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n",
    "            bounding_importance_fracs.append(bounding_importance_frac)\n",
    "            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n",
    "            dominant_blues.append(dominant_blue)\n",
    "            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n",
    "            dominant_greens.append(dominant_green)\n",
    "            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n",
    "            dominant_reds.append(dominant_red)\n",
    "            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n",
    "            dominant_pixel_fracs.append(dominant_pixel_frac)\n",
    "            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n",
    "            dominant_scores.append(dominant_score)\n",
    "            if data.get('labelAnnotations'):\n",
    "                label_description = data['labelAnnotations'][0]['description']\n",
    "                label_descriptions.append(label_description)\n",
    "                label_score = data['labelAnnotations'][0]['score']\n",
    "                label_scores.append(label_score)\n",
    "            else:\n",
    "                nl_count += 1\n",
    "                label_descriptions.append('nothing')\n",
    "                label_scores.append(-1)\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        vertex_xs.append(-1)\n",
    "        vertex_ys.append(-1)\n",
    "        bounding_confidences.append(-1)\n",
    "        bounding_importance_fracs.append(-1)\n",
    "        dominant_blues.append(-1)\n",
    "        dominant_greens.append(-1)\n",
    "        dominant_reds.append(-1)\n",
    "        dominant_pixel_fracs.append(-1)\n",
    "        dominant_scores.append(-1)\n",
    "        label_descriptions.append('nothing')\n",
    "        label_scores.append(-1)\n",
    "        pass\n",
    "\n",
    "print(nf_count)\n",
    "test.loc[:, 'vertex_x'] = vertex_xs\n",
    "test.loc[:, 'vertex_y'] = vertex_ys\n",
    "test.loc[:, 'bounding_confidence'] = bounding_confidences\n",
    "test.loc[:, 'bounding_importance'] = bounding_importance_fracs\n",
    "test.loc[:, 'dominant_blue'] = dominant_blues\n",
    "test.loc[:, 'dominant_green'] = dominant_greens\n",
    "test.loc[:, 'dominant_red'] = dominant_reds\n",
    "test.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n",
    "test.loc[:, 'dominant_score'] = dominant_scores\n",
    "test.loc[:, 'label_description'] = label_descriptions\n",
    "test.loc[:, 'label_score'] = label_scores\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)\n",
    "test.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)\n",
    "\n",
    "train.drop(['dominant_green', 'doc_sent_score', 'FurLength', 'Vaccinated', \n",
    "               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type',\n",
    "           'bounding_importance', 'bounding_confidence', 'pic_79',\n",
    "           'pic_252', 'pic_109', 'pic_197', 'pic_17', 'pic_104', 'pic_59', 'label_description'], axis=1, inplace=True)\n",
    "test.drop(['dominant_green', 'doc_sent_score', 'FurLength', 'Vaccinated', \n",
    "               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type',\n",
    "           'bounding_importance', 'bounding_confidence', 'pic_79',\n",
    "           'pic_252', 'pic_109', 'pic_197', 'pic_17', 'pic_104', 'pic_59', 'label_description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14720, 469)\n",
      "(3948, 469)\n",
      "saved train csv image, metadata, sentiment merged\n",
      "saved test csv image, metadata, sentiment merged\n",
      "getting categorical features\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', \n",
    "                'doc_sent_mag', 'doc_sent_score', 'dominant_score', 'dominant_pixel_frac', \n",
    "                'dominant_red', 'dominant_green', 'dominant_blue', 'bounding_importance', \n",
    "                'bounding_confidence', 'vertex_x', 'vertex_y', 'label_score'] +\\\n",
    "               [col for col in train.columns if col.startswith('pic') or col.startswith('svd')]\n",
    "cat_cols = list(set(train.columns) - set(numeric_cols))\n",
    "train.loc[:, cat_cols] = train[cat_cols].astype('category')\n",
    "test.loc[:, cat_cols] = test[cat_cols].astype('category')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "#print(test.head())\n",
    "drop = \"_drop100\"\n",
    "train.to_csv(r'csv_out/train_ims_merged' + drop + '.csv')\n",
    "print(\"saved train csv image, metadata, sentiment merged\")\n",
    "test.to_csv(r'csv_out/test_ims_merged' + drop +'.csv')\n",
    "print(\"saved test csv image, metadata, sentiment merged\")\n",
    "print(\"getting categorical features\")\n",
    "# get the categorical features\n",
    "foo = train.dtypes\n",
    "cat_feature_names = foo[foo == \"category\"]\n",
    "cat_features = [train.columns.get_loc(c) for c in train.columns if c in cat_feature_names]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run LightGBM Train Model\n",
      "Started lgb fold 1/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.04084\tvalid_1's rmse: 1.09391\n",
      "[200]\ttraining's rmse: 0.965753\tvalid_1's rmse: 1.06837\n",
      "[300]\ttraining's rmse: 0.914011\tvalid_1's rmse: 1.05779\n",
      "[400]\ttraining's rmse: 0.87058\tvalid_1's rmse: 1.05167\n",
      "[500]\ttraining's rmse: 0.836749\tvalid_1's rmse: 1.04782\n",
      "[600]\ttraining's rmse: 0.807803\tvalid_1's rmse: 1.04604\n",
      "[700]\ttraining's rmse: 0.777991\tvalid_1's rmse: 1.04441\n",
      "[800]\ttraining's rmse: 0.749481\tvalid_1's rmse: 1.04385\n",
      "[900]\ttraining's rmse: 0.723822\tvalid_1's rmse: 1.04309\n",
      "[1000]\ttraining's rmse: 0.69892\tvalid_1's rmse: 1.04303\n",
      "[1100]\ttraining's rmse: 0.676189\tvalid_1's rmse: 1.04316\n",
      "[1200]\ttraining's rmse: 0.654646\tvalid_1's rmse: 1.04298\n",
      "[1300]\ttraining's rmse: 0.63375\tvalid_1's rmse: 1.04288\n",
      "[1400]\ttraining's rmse: 0.614807\tvalid_1's rmse: 1.04289\n",
      "[1500]\ttraining's rmse: 0.597068\tvalid_1's rmse: 1.04306\n",
      "[1600]\ttraining's rmse: 0.579241\tvalid_1's rmse: 1.0433\n",
      "[1700]\ttraining's rmse: 0.56177\tvalid_1's rmse: 1.04333\n",
      "[1800]\ttraining's rmse: 0.544592\tvalid_1's rmse: 1.04369\n",
      "Early stopping, best iteration is:\n",
      "[1222]\ttraining's rmse: 0.649754\tvalid_1's rmse: 1.04276\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 826, 2: 791, 3: 641, 1: 608, 0: 80})\n",
      "Predicted Counts =  Counter({2.0: 1355, 4.0: 743, 3.0: 678, 1.0: 170})\n",
      "Coefficients =  [0.51896237 1.74984786 2.5189254  2.86709483]\n",
      "QWK =  0.4292919077024141\n",
      "Predict 2/2\n",
      "lgb cv score 1: RMSE 1.0427583914345704 QWK 0.4292919077024141\n",
      "Started lgb fold 2/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03943\tvalid_1's rmse: 1.09915\n",
      "[200]\ttraining's rmse: 0.964991\tvalid_1's rmse: 1.07676\n",
      "[300]\ttraining's rmse: 0.912249\tvalid_1's rmse: 1.067\n",
      "[400]\ttraining's rmse: 0.869413\tvalid_1's rmse: 1.06285\n",
      "[500]\ttraining's rmse: 0.833839\tvalid_1's rmse: 1.06029\n",
      "[600]\ttraining's rmse: 0.803624\tvalid_1's rmse: 1.05955\n",
      "[700]\ttraining's rmse: 0.774878\tvalid_1's rmse: 1.05926\n",
      "[800]\ttraining's rmse: 0.747557\tvalid_1's rmse: 1.05874\n",
      "[900]\ttraining's rmse: 0.72294\tvalid_1's rmse: 1.05861\n",
      "[1000]\ttraining's rmse: 0.699911\tvalid_1's rmse: 1.05876\n",
      "[1100]\ttraining's rmse: 0.678402\tvalid_1's rmse: 1.05853\n",
      "[1200]\ttraining's rmse: 0.657311\tvalid_1's rmse: 1.05851\n",
      "[1300]\ttraining's rmse: 0.63607\tvalid_1's rmse: 1.05849\n",
      "[1400]\ttraining's rmse: 0.616601\tvalid_1's rmse: 1.05843\n",
      "[1500]\ttraining's rmse: 0.597772\tvalid_1's rmse: 1.05911\n",
      "[1600]\ttraining's rmse: 0.577968\tvalid_1's rmse: 1.0593\n",
      "[1700]\ttraining's rmse: 0.559231\tvalid_1's rmse: 1.05957\n",
      "Early stopping, best iteration is:\n",
      "[1138]\ttraining's rmse: 0.669899\tvalid_1's rmse: 1.0583\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 826, 2: 791, 3: 641, 1: 608, 0: 80})\n",
      "Predicted Counts =  Counter({2.0: 1342, 3.0: 737, 4.0: 676, 1.0: 191})\n",
      "Coefficients =  [0.50968421 1.77223517 2.50539515 2.92769341]\n",
      "QWK =  0.4047397522062528\n",
      "Predict 2/2\n",
      "lgb cv score 2: RMSE 1.0583042805666343 QWK 0.4047397522062528\n",
      "Started lgb fold 3/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.04006\tvalid_1's rmse: 1.09996\n",
      "[200]\ttraining's rmse: 0.964893\tvalid_1's rmse: 1.07498\n",
      "[300]\ttraining's rmse: 0.910559\tvalid_1's rmse: 1.06355\n",
      "[400]\ttraining's rmse: 0.867815\tvalid_1's rmse: 1.05838\n",
      "[500]\ttraining's rmse: 0.830995\tvalid_1's rmse: 1.05519\n",
      "[600]\ttraining's rmse: 0.799863\tvalid_1's rmse: 1.05257\n",
      "[700]\ttraining's rmse: 0.770883\tvalid_1's rmse: 1.05121\n",
      "[800]\ttraining's rmse: 0.743874\tvalid_1's rmse: 1.04991\n",
      "[900]\ttraining's rmse: 0.71792\tvalid_1's rmse: 1.04935\n",
      "[1000]\ttraining's rmse: 0.692925\tvalid_1's rmse: 1.04861\n",
      "[1100]\ttraining's rmse: 0.669265\tvalid_1's rmse: 1.04832\n",
      "[1200]\ttraining's rmse: 0.647364\tvalid_1's rmse: 1.04837\n",
      "[1300]\ttraining's rmse: 0.625744\tvalid_1's rmse: 1.04842\n",
      "[1400]\ttraining's rmse: 0.604596\tvalid_1's rmse: 1.04849\n",
      "[1500]\ttraining's rmse: 0.585075\tvalid_1's rmse: 1.04859\n",
      "[1600]\ttraining's rmse: 0.565442\tvalid_1's rmse: 1.04881\n",
      "[1700]\ttraining's rmse: 0.546799\tvalid_1's rmse: 1.04888\n",
      "[1800]\ttraining's rmse: 0.529474\tvalid_1's rmse: 1.04896\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttraining's rmse: 0.637837\tvalid_1's rmse: 1.04799\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 826, 2: 791, 3: 640, 1: 608, 0: 79})\n",
      "Predicted Counts =  Counter({2.0: 1557, 4.0: 820, 3.0: 468, 1.0: 99})\n",
      "Coefficients =  [0.52623307 1.67258612 2.5678649  2.81407114]\n",
      "QWK =  0.41362727249075204\n",
      "Predict 2/2\n",
      "lgb cv score 3: RMSE 1.0479949153981478 QWK 0.41362727249075204\n",
      "Started lgb fold 4/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03962\tvalid_1's rmse: 1.09666\n",
      "[200]\ttraining's rmse: 0.965072\tvalid_1's rmse: 1.06827\n",
      "[300]\ttraining's rmse: 0.911996\tvalid_1's rmse: 1.05432\n",
      "[400]\ttraining's rmse: 0.869446\tvalid_1's rmse: 1.04679\n",
      "[500]\ttraining's rmse: 0.834647\tvalid_1's rmse: 1.04306\n",
      "[600]\ttraining's rmse: 0.803773\tvalid_1's rmse: 1.04085\n",
      "[700]\ttraining's rmse: 0.776717\tvalid_1's rmse: 1.03956\n",
      "[800]\ttraining's rmse: 0.750434\tvalid_1's rmse: 1.0386\n",
      "[900]\ttraining's rmse: 0.72572\tvalid_1's rmse: 1.03804\n",
      "[1000]\ttraining's rmse: 0.703729\tvalid_1's rmse: 1.03752\n",
      "[1100]\ttraining's rmse: 0.682189\tvalid_1's rmse: 1.03704\n",
      "[1200]\ttraining's rmse: 0.660931\tvalid_1's rmse: 1.03639\n",
      "[1300]\ttraining's rmse: 0.641308\tvalid_1's rmse: 1.03692\n",
      "[1400]\ttraining's rmse: 0.621574\tvalid_1's rmse: 1.0366\n",
      "[1500]\ttraining's rmse: 0.602505\tvalid_1's rmse: 1.03659\n",
      "[1600]\ttraining's rmse: 0.584552\tvalid_1's rmse: 1.03628\n",
      "[1700]\ttraining's rmse: 0.567102\tvalid_1's rmse: 1.03612\n",
      "[1800]\ttraining's rmse: 0.549451\tvalid_1's rmse: 1.03608\n",
      "[1900]\ttraining's rmse: 0.530871\tvalid_1's rmse: 1.03622\n",
      "[2000]\ttraining's rmse: 0.515259\tvalid_1's rmse: 1.03616\n",
      "[2100]\ttraining's rmse: 0.498302\tvalid_1's rmse: 1.03607\n",
      "[2200]\ttraining's rmse: 0.483597\tvalid_1's rmse: 1.03604\n",
      "[2300]\ttraining's rmse: 0.469628\tvalid_1's rmse: 1.03632\n",
      "[2400]\ttraining's rmse: 0.455205\tvalid_1's rmse: 1.03618\n",
      "[2500]\ttraining's rmse: 0.441642\tvalid_1's rmse: 1.03611\n",
      "[2600]\ttraining's rmse: 0.428241\tvalid_1's rmse: 1.03608\n",
      "[2700]\ttraining's rmse: 0.415343\tvalid_1's rmse: 1.03606\n",
      "Early stopping, best iteration is:\n",
      "[2171]\ttraining's rmse: 0.487864\tvalid_1's rmse: 1.03587\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 825, 2: 791, 3: 640, 1: 607, 0: 79})\n",
      "Predicted Counts =  Counter({2.0: 810, 4.0: 793, 3.0: 720, 1.0: 617, 0.0: 2})\n",
      "Coefficients =  [0.47513596 2.07118772 2.45003921 2.8323247 ]\n",
      "QWK =  0.45003003556620713\n",
      "Predict 2/2\n",
      "lgb cv score 4: RMSE 1.0358726239567113 QWK 0.45003003556620713\n",
      "Started lgb fold 5/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.04108\tvalid_1's rmse: 1.0906\n",
      "[200]\ttraining's rmse: 0.965861\tvalid_1's rmse: 1.06338\n",
      "[300]\ttraining's rmse: 0.914826\tvalid_1's rmse: 1.05328\n",
      "[400]\ttraining's rmse: 0.872472\tvalid_1's rmse: 1.04747\n",
      "[500]\ttraining's rmse: 0.837458\tvalid_1's rmse: 1.04408\n",
      "[600]\ttraining's rmse: 0.80573\tvalid_1's rmse: 1.04234\n",
      "[700]\ttraining's rmse: 0.776965\tvalid_1's rmse: 1.04097\n",
      "[800]\ttraining's rmse: 0.748866\tvalid_1's rmse: 1.04028\n",
      "[900]\ttraining's rmse: 0.721613\tvalid_1's rmse: 1.03991\n",
      "[1000]\ttraining's rmse: 0.697298\tvalid_1's rmse: 1.03939\n",
      "[1100]\ttraining's rmse: 0.6749\tvalid_1's rmse: 1.03906\n",
      "[1200]\ttraining's rmse: 0.652837\tvalid_1's rmse: 1.03882\n",
      "[1300]\ttraining's rmse: 0.632131\tvalid_1's rmse: 1.03836\n",
      "[1400]\ttraining's rmse: 0.611143\tvalid_1's rmse: 1.03846\n",
      "[1500]\ttraining's rmse: 0.592863\tvalid_1's rmse: 1.0385\n",
      "[1600]\ttraining's rmse: 0.574033\tvalid_1's rmse: 1.03857\n",
      "[1700]\ttraining's rmse: 0.555655\tvalid_1's rmse: 1.03854\n",
      "[1800]\ttraining's rmse: 0.539566\tvalid_1's rmse: 1.03847\n",
      "[1900]\ttraining's rmse: 0.523986\tvalid_1's rmse: 1.03869\n",
      "[2000]\ttraining's rmse: 0.509416\tvalid_1's rmse: 1.03894\n",
      "Early stopping, best iteration is:\n",
      "[1445]\ttraining's rmse: 0.603125\tvalid_1's rmse: 1.03826\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 825, 2: 791, 3: 640, 1: 607, 0: 79})\n",
      "Predicted Counts =  Counter({2.0: 1370, 4.0: 714, 3.0: 704, 1.0: 154})\n",
      "Coefficients =  [0.52369394 1.71103155 2.52251023 2.90283216]\n",
      "QWK =  0.4295466493450164\n",
      "Predict 2/2\n",
      "lgb cv score 5: RMSE 1.0382622152995136 QWK 0.4295466493450164\n",
      "lgb cv RMSE scores : [1.0427583914345704, 1.0583042805666343, 1.0479949153981478, 1.0358726239567113, 1.0382622152995136]\n",
      "lgb cv mean RMSE score : 1.0446384853311155\n",
      "lgb cv std RMSE score : 1.0446384853311155\n",
      "lgb cv QWK scores : [0.4292919077024141, 0.4047397522062528, 0.41362727249075204, 0.45003003556620713, 0.4295466493450164]\n",
      "lgb cv mean QWK score : 0.4254471234621285\n",
      "lgb cv std QWK score : 0.01552038754123033\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 5\n",
    "def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, random_state=42, shuffle=True)\n",
    "    fold_splits = kf.split(train, target)\n",
    "    cv_scores = []\n",
    "    qwk_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros((train.shape[0], N_SPLITS))\n",
    "    all_coefficients = np.zeros((N_SPLITS, 4))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    i = 1\n",
    "    for dev_index, val_index in fold_splits:\n",
    "        print('Started ' + label + ' fold ' + str(i) + '/' + str(N_SPLITS))\n",
    "        if isinstance(train, pd.DataFrame):\n",
    "            dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        else:\n",
    "            dev_X, val_X = train[dev_index], train[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        params2 = params.copy()\n",
    "        pred_val_y, pred_test_y, importances, coefficients, qwk = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index] = pred_val_y\n",
    "        all_coefficients[i-1, :] = coefficients\n",
    "        if eval_fn is not None:\n",
    "            cv_score = eval_fn(val_y, pred_val_y)\n",
    "            cv_scores.append(cv_score)\n",
    "            qwk_scores.append(qwk)\n",
    "            print(label + ' cv score {}: RMSE {} QWK {}'.format(i, cv_score, qwk))\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = train.columns.values\n",
    "        fold_importance_df['importance'] = importances\n",
    "        fold_importance_df['fold'] = i\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)        \n",
    "        i += 1\n",
    "    print('{} cv RMSE scores : {}'.format(label, cv_scores))\n",
    "    print('{} cv mean RMSE score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv std RMSE score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv QWK scores : {}'.format(label, qwk_scores))\n",
    "    print('{} cv mean QWK score : {}'.format(label, np.mean(qwk_scores)))\n",
    "    print('{} cv std QWK score : {}'.format(label, np.std(qwk_scores)))\n",
    "    pred_full_test = pred_full_test / float(N_SPLITS)\n",
    "    results = {'label': label,\n",
    "               'train': pred_train, 'test': pred_full_test,\n",
    "                'cv': cv_scores, 'qwk': qwk_scores,\n",
    "               'importance': feature_importance_df,\n",
    "               'coefficients': all_coefficients}\n",
    "    return results\n",
    "\n",
    "params = {'application': 'regression',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves': 70,\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.85,\n",
    "          'feature_fraction': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'min_child_samples': 150,\n",
    "          'min_child_weight': 0.02,\n",
    "          'lambda_l2': 0.0475,\n",
    "          'verbosity': -1,\n",
    "          'data_random_seed': 17,\n",
    "          'early_stop': 600,\n",
    "          'verbose_eval': 100,\n",
    "          'num_rounds': 10000}\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y, test_X2, params):\n",
    "    print('Prep LGB')\n",
    "    d_train = lgb.Dataset(train_X, label=train_y)\n",
    "    d_valid = lgb.Dataset(test_X, label=test_y)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    print('Train LGB')\n",
    "    num_rounds = params.pop('num_rounds')\n",
    "    verbose_eval = params.pop('verbose_eval')\n",
    "    early_stop = None\n",
    "    if params.get('early_stop'):\n",
    "        early_stop = params.pop('early_stop')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                      categorical_feature=list(cat_features),\n",
    "                      early_stopping_rounds=early_stop)\n",
    "    \n",
    "    print('Predict 1/2')\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(pred_test_y, test_y)\n",
    "    coefficients = optR.coefficients()\n",
    "    pred_test_y_k = optR.predict(pred_test_y, coefficients)\n",
    "    print(\"Valid Counts = \", Counter(test_y))\n",
    "    print(\"Predicted Counts = \", Counter(pred_test_y_k))\n",
    "    print(\"Coefficients = \", coefficients)\n",
    "    qwk = quadratic_weighted_kappa(test_y, pred_test_y_k)\n",
    "    print(\"QWK = \", qwk)\n",
    "    print('Predict 2/2')\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "    return pred_test_y.reshape(-1, 1), pred_test_y2.reshape(-1, 1), model.feature_importance(), coefficients, qwk\n",
    "\n",
    "print(\"Run LightGBM Train Model\")\n",
    "results = run_cv_model(train, test, target, runLGB, params, rmse, 'lgb')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breed1</td>\n",
       "      <td>1266.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>label_score</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breed2</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>vertex_y</td>\n",
       "      <td>415.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>State</td>\n",
       "      <td>392.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quantity</td>\n",
       "      <td>330.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>svd_46</td>\n",
       "      <td>274.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>svd_133</td>\n",
       "      <td>233.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>vertex_x</td>\n",
       "      <td>217.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>svd_70</td>\n",
       "      <td>216.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>pic_31</td>\n",
       "      <td>216.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>svd_40</td>\n",
       "      <td>210.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>svd_30</td>\n",
       "      <td>210.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>svd_162</td>\n",
       "      <td>201.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>svd_181</td>\n",
       "      <td>197.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>svd_111</td>\n",
       "      <td>195.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>svd_155</td>\n",
       "      <td>192.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>svd_144</td>\n",
       "      <td>191.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fee</td>\n",
       "      <td>191.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>svd_96</td>\n",
       "      <td>190.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pic_121</td>\n",
       "      <td>190.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>svd_69</td>\n",
       "      <td>190.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>svd_151</td>\n",
       "      <td>187.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doc_sent_mag</td>\n",
       "      <td>187.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>svd_81</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>svd_174</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>svd_21</td>\n",
       "      <td>182.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>svd_3</td>\n",
       "      <td>181.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>svd_100</td>\n",
       "      <td>181.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>pic_254</td>\n",
       "      <td>57.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>pic_191</td>\n",
       "      <td>57.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>pic_60</td>\n",
       "      <td>56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pic_122</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>pic_250</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>pic_204</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>pic_87</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>pic_202</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>pic_215</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>pic_235</td>\n",
       "      <td>50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>pic_173</td>\n",
       "      <td>50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pic_176</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>pic_83</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>pic_183</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>pic_247</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>pic_220</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>pic_151</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>pic_251</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>pic_185</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pic_169</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pic_175</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>pic_246</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>pic_189</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>pic_209</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pic_216</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pic_212</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>pic_242</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>pic_193</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>pic_23</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pic_172</td>\n",
       "      <td>40.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "1          Breed1      1266.8\n",
       "0             Age       741.0\n",
       "17    label_score       502.0\n",
       "2          Breed2       436.0\n",
       "468      vertex_y       415.6\n",
       "10          State       392.2\n",
       "9        Quantity       330.6\n",
       "408        svd_46       274.6\n",
       "306       svd_133       233.6\n",
       "467      vertex_x       217.8\n",
       "435        svd_70       216.6\n",
       "194        pic_31       216.4\n",
       "402        svd_40       210.4\n",
       "391        svd_30       210.2\n",
       "338       svd_162       201.8\n",
       "359       svd_181       197.2\n",
       "282       svd_111       195.6\n",
       "330       svd_155       192.6\n",
       "318       svd_144       191.4\n",
       "5             Fee       191.4\n",
       "463        svd_96       190.8\n",
       "42        pic_121       190.8\n",
       "433        svd_69       190.8\n",
       "326       svd_151       187.6\n",
       "12   doc_sent_mag       187.4\n",
       "447        svd_81       184.0\n",
       "351       svd_174       183.0\n",
       "381        svd_21       182.4\n",
       "390         svd_3       181.8\n",
       "270       svd_100       181.4\n",
       "..            ...         ...\n",
       "186       pic_254        57.2\n",
       "118       pic_191        57.2\n",
       "225        pic_60        56.8\n",
       "43        pic_122        56.0\n",
       "183       pic_250        56.0\n",
       "132       pic_204        55.8\n",
       "253        pic_87        55.6\n",
       "130       pic_202        52.2\n",
       "144       pic_215        52.0\n",
       "166       pic_235        50.6\n",
       "98        pic_173        50.6\n",
       "101       pic_176        50.2\n",
       "249        pic_83        50.0\n",
       "109       pic_183        49.6\n",
       "179       pic_247        49.6\n",
       "150       pic_220        49.6\n",
       "75        pic_151        49.6\n",
       "184       pic_251        48.4\n",
       "111       pic_185        48.0\n",
       "94        pic_169        47.2\n",
       "100       pic_175        47.0\n",
       "178       pic_246        46.0\n",
       "115       pic_189        45.4\n",
       "137       pic_209        45.4\n",
       "145       pic_216        44.6\n",
       "141       pic_212        42.0\n",
       "174       pic_242        41.4\n",
       "120       pic_193        40.6\n",
       "160        pic_23        40.6\n",
       "97        pic_172        40.2\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports = results['importance'].groupby('feature')['feature', 'importance'].mean().reset_index()\n",
    "imports.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving out feature importance list to CSV\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"saving out feature importance list to CSV\")\n",
    "imports.to_csv(\"csv_out/features_importance.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51074191 1.79537768 2.51294698 2.86880325]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({3: 3089, 2: 4259, 4: 3954, 1: 2924, 0: 494})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "coefficients_ = np.mean(results['coefficients'], axis=0)\n",
    "print(coefficients_)\n",
    "# manually adjust coefs\n",
    "coefficients_[0] = 1.645\n",
    "coefficients_[1] = 2.115\n",
    "coefficients_[3] = 2.84\n",
    "train_predictions = [r[0] for r in results['train']]\n",
    "train_predictions = optR.predict(train_predictions, coefficients_).astype(int)\n",
    "Counter(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51074191 1.79537768 2.51294698 2.86880325]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({3: 897, 4: 1136, 2: 1125, 1: 724, 0: 66})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "coefficients_ = np.mean(results['coefficients'], axis=0)\n",
    "print(coefficients_)\n",
    "# manually adjust coefs\n",
    "coefficients_[0] = 1.645\n",
    "coefficients_[1] = 2.115\n",
    "coefficients_[3] = 2.84\n",
    "test_predictions = [r[0] for r in results['test']]\n",
    "test_predictions = optR.predict(test_predictions, coefficients_).astype(int)\n",
    "Counter(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Distribution:\n",
      "0    0.026970\n",
      "1    0.206386\n",
      "2    0.268682\n",
      "3    0.217527\n",
      "4    0.280435\n",
      "Name: AdoptionSpeed, dtype: float64\n",
      "Test Predicted Distribution:\n",
      "0    0.016717\n",
      "1    0.183384\n",
      "2    0.284954\n",
      "3    0.227204\n",
      "4    0.287741\n",
      "dtype: float64\n",
      "Train Predicted Distribution:\n",
      "0    0.033560\n",
      "1    0.198641\n",
      "2    0.289334\n",
      "3    0.209851\n",
      "4    0.268614\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"True Distribution:\")\n",
    "print(pd.value_counts(target, normalize=True).sort_index())\n",
    "print(\"Test Predicted Distribution:\")\n",
    "print(pd.value_counts(test_predictions, normalize=True).sort_index())\n",
    "print(\"Train Predicted Distribution:\")\n",
    "print(pd.value_counts(train_predictions, normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>114</td>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>1064</td>\n",
       "      <td>1006</td>\n",
       "      <td>463</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>957</td>\n",
       "      <td>1425</td>\n",
       "      <td>801</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>556</td>\n",
       "      <td>1039</td>\n",
       "      <td>832</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>233</td>\n",
       "      <td>679</td>\n",
       "      <td>929</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4\n",
       "0   58   114   110   64    51\n",
       "1  229  1064  1006  463   276\n",
       "2  132   957  1425  801   640\n",
       "3   62   556  1039  832   713\n",
       "4   13   233   679  929  2274"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sk_cmatrix(target, train_predictions), index=list(range(5)), columns=list(range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              3\n",
       "1  73c10e136              4\n",
       "2  72000c4c5              4\n",
       "3  e147a4b9f              3\n",
       "4  43fbba852              4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_weighted_kappa(target, train_predictions)\n",
    "rmse(target, [r[0] for r in results['train']])\n",
    "submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/LightBGM with image features/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
