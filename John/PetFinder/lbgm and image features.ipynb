{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import lightgbm as lgb\n",
    "np.random.seed(369)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "def rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "import tensorflow as tf\n",
    "\n",
    "train_df = pd.read_csv('input/train/train.csv')\n",
    "img_size = 256\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = train_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # new_size should be in (width, height) format\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "def train_keras():\n",
    "    from keras.models import Model\n",
    "    from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #https://regressionsessionsblog.wordpress.com/2018/06/11/stuck-on-an-issue-making-keras-predictions-in-parallel/\n",
    "    #https://github.com/keras-team/keras/issues/4740\n",
    "    jobs = 6\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=jobs, \\\n",
    "                            inter_op_parallelism_threads=jobs, \\\n",
    "                            allow_soft_placement=True, \\\n",
    "                            device_count = {'CPU': jobs})\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "\n",
    "    print(\"start\")\n",
    "    inp = Input((256,256,3))\n",
    "    backbone = DenseNet121(input_tensor = inp, \n",
    "                            weights=\"input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n",
    "                            include_top = False)\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "    x = AveragePooling1D(4)(x)\n",
    "    out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "    m = Model(inp,out)\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"start keras prediction\")\n",
    "\n",
    "    for b in tqdm_notebook(range(n_batches)):\n",
    "        start = b*batch_size\n",
    "        end = (b+1)*batch_size\n",
    "        batch_pets = pet_ids[start:end]\n",
    "        batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            try:\n",
    "                batch_images[i] = load_image(\"input/train/train_images/\", pet_id)\n",
    "            except:\n",
    "                pass\n",
    "        batch_preds = m.predict(batch_images)\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            features[pet_id] = batch_preds[i]\n",
    "    print(\"done keras prediction\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "done\n",
      "start keras prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e67e192f3af4941a9a55ca75f1ae3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done keras prediction\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "m = train_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(features, filename=\"train_features\"):\n",
    "    with open(filename + \".json\", 'w') as file:\n",
    "        json.dump(features,file)\n",
    "        #json.dump(dictionary, file, sort_keys=True, indent=4)\n",
    "    return\n",
    "def load_json(filename=\"file\", dictionary=features):\n",
    "    with open(filename + \".json\", 'r') as file:\n",
    "        loaded_file = json.load(file)\n",
    "    return loaded_file\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)): #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "dumped = json.dumps(features, cls=NumpyEncoder)\n",
    "\n",
    "with open(\"train_features.json\", 'w') as f:\n",
    "    json.dump(dumped, f)\n",
    "    print(\"Saved train features json to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model weights to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(m.summary())\n",
    "\n",
    "m.save_weights(\"keras_model_weights.h5\")\n",
    "print(\"Saved model weights to disk\")\n",
    "#with open(\"train_features.json\", 'r') as f:\n",
    "#    train_loaded_features = json.load(f)\n",
    "#    train_loaded_features = json.loads(train_loaded_features)\n",
    "#    print(\"loaded train features\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start create model\n",
      "done\n",
      "start keras test prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087b36f307d34e90a643ec0bb94c3825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done keras test prediction\n",
      "Saved test features json to disk\n"
     ]
    }
   ],
   "source": [
    "train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "train_feats.columns = ['pic_'+str(i) for i in range(train_feats.shape[1])]\n",
    "test_df = pd.read_csv('input/test/test.csv')\n",
    "\n",
    "pet_ids = test_df['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "test_features = {}\n",
    "\n",
    "def train_test_keras(m, n_batches):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #https://regressionsessionsblog.wordpress.com/2018/06/11/stuck-on-an-issue-making-keras-predictions-in-parallel/\n",
    "    #https://github.com/keras-team/keras/issues/4740\n",
    "    jobs = 6\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=jobs, \\\n",
    "                            inter_op_parallelism_threads=jobs, \\\n",
    "                            allow_soft_placement=True, \\\n",
    "                            device_count = {'CPU': jobs})\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "\n",
    "    print(\"start create model\")\n",
    "    inp = Input((256,256,3))\n",
    "    backbone = DenseNet121(input_tensor = inp, \n",
    "                            weights=\"input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n",
    "                            include_top = False)\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "    x = AveragePooling1D(4)(x)\n",
    "    out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "    m = Model(inp,out)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"start keras test prediction\")\n",
    "\n",
    "    for b in tqdm_notebook(range(n_batches)):\n",
    "        start = b*batch_size\n",
    "        end = (b+1)*batch_size\n",
    "        batch_pets = pet_ids[start:end]\n",
    "        batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            try:\n",
    "                batch_images[i] = load_image(\"input/test/test_images/\", pet_id)\n",
    "            except:\n",
    "                pass\n",
    "        batch_preds = m.predict(batch_images)\n",
    "        for i,pet_id in enumerate(batch_pets):\n",
    "            test_features[pet_id] = batch_preds[i]\n",
    "    print(\"done keras test prediction\")\n",
    "    return\n",
    "\n",
    "train_test_keras(m, n_batches)\n",
    "\n",
    "dumped = json.dumps(test_features, cls=NumpyEncoder)\n",
    "\n",
    "with open(\"test_features.json\", 'w') as f:\n",
    "    json.dump(dumped, f)\n",
    "    print(\"Saved test features json to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved image test features prediction values to CSV\n"
     ]
    }
   ],
   "source": [
    "test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "test_feats.columns = ['pic_'+str(i) for i in range(test_feats.shape[1])]\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "test_feats.head()\n",
    "\n",
    "test_feats.to_csv(r'csv_out/img_test_feats_prediction_values.csv')\n",
    "print(\"saved image test features prediction values to CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train features\n",
      "loaded test features\n",
      "creating dataframes from feature dictionaries\n",
      "joining dataframes\n",
      "saved train csv image merge\n",
      "saved test csv image merge\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train/train.csv\")\n",
    "test = pd.read_csv(\"input/test/test.csv\")\n",
    "\n",
    "target = train['AdoptionSpeed']\n",
    "train_id = train['PetID']\n",
    "test_id = test['PetID']\n",
    "\n",
    "loaded_train_feats = {}\n",
    "loaded_test_feats = {}\n",
    "with open(\"train_features.json\", 'r') as f:\n",
    "    loaded_train_feats = json.load(f)\n",
    "    loaded_train_feats = json.loads(loaded_train_feats)\n",
    "    print(\"loaded train features\")\n",
    "\n",
    "with open(\"test_features.json\", 'r') as f:\n",
    "    loaded_test_feats = json.load(f)\n",
    "    loaded_test_feats = json.loads(loaded_test_feats)\n",
    "    print(\"loaded test features\") \n",
    "\n",
    "print(\"creating dataframes from feature dictionaries\")\n",
    "train_feats = pd.DataFrame.from_dict(loaded_train_feats, orient='index')\n",
    "train_feats.columns = ['pic_'+str(i) for i in range(train_feats.shape[1])]\n",
    "\n",
    "test_feats = pd.DataFrame.from_dict(loaded_test_feats, orient='index')\n",
    "test_feats.columns = ['pic_'+str(i) for i in range(test_feats.shape[1])]\n",
    "\n",
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "print(\"joining dataframes\")\n",
    "train = train.join(train_feats.set_index('PetID'),on='PetID')\n",
    "test = test.join(test_feats.set_index('PetID'),on='PetID')\n",
    "#train = pd.merge(train, train_feats, on = ['PetID'], how = 'left')\n",
    "#test = pd.merge(test, test_feats, left_on = ['PetID'], right_on = ['PetID'], how = 'outer')\n",
    "\n",
    "train.drop(['AdoptionSpeed', 'PetID'], axis=1, inplace=True)\n",
    "test.drop(['PetID'], axis=1, inplace=True)\n",
    "\n",
    "#prepared = train\n",
    "#prepared.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "\n",
    "#train.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "#test.drop(['RescuerID', 'Name', 'Description', 'Vaccinated', \n",
    "#               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type'], axis=1, inplace=True)\n",
    "\n",
    "#prepared.to_csv(r'csv_out/cleaned_img_merge.csv')\n",
    "#print(\"saved prepared csv\")\n",
    "train.to_csv(r'csv_out/train_csv_img_merge.csv')\n",
    "print(\"saved train csv image merge\")\n",
    "test.to_csv(r'csv_out/test_csv_img_merge.csv')\n",
    "print(\"saved test csv image merge\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sentiment train\n",
      "loading sentiment test\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "doc_sent_mag = []\n",
    "doc_sent_score = []\n",
    "nf_count = 0\n",
    "print(\"loading sentiment train\")\n",
    "for petid in train_id:\n",
    "    try:\n",
    "        with open('input/train/train_sentiment/' + petid + '.json', 'r') as f:\n",
    "            sentiment = json.load(f)\n",
    "        doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n",
    "        doc_sent_score.append(sentiment['documentSentiment']['score'])\n",
    "    except  Exception:\n",
    "        nf_count += 1\n",
    "        doc_sent_mag.append(-1)\n",
    "        doc_sent_score.append(-1)\n",
    "        pass\n",
    "\n",
    "train.loc[:, 'doc_sent_mag'] = doc_sent_mag\n",
    "train.loc[:, 'doc_sent_score'] = doc_sent_score\n",
    "\n",
    "doc_sent_mag = []\n",
    "doc_sent_score = []\n",
    "nf_count = 0\n",
    "print(\"loading sentiment test\")\n",
    "for petid in test_id:\n",
    "    try:\n",
    "        with open('input/test/test_sentiment/' + petid + '.json', 'r') as f:\n",
    "            sentiment = json.load(f)\n",
    "        doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n",
    "        doc_sent_score.append(sentiment['documentSentiment']['score'])\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        doc_sent_mag.append(-1)\n",
    "        doc_sent_score.append(-1)\n",
    "        pass\n",
    "\n",
    "test.loc[:, 'doc_sent_mag'] = doc_sent_mag\n",
    "test.loc[:, 'doc_sent_score'] = doc_sent_score\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit training sentiment descriptions\n",
      "X (tfidf): (14993, 10000)\n",
      "X (svd): (14993, 200)\n",
      "train: (14993, 480)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"scikit training sentiment descriptions\")\n",
    "## WITHOUT ERROR FIXED\n",
    "train_desc = train.Description.fillna(\"none\").values\n",
    "test_desc = test.Description.fillna(\"none\").values\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=10000,\n",
    "        strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "    \n",
    "# Fit TFIDF\n",
    "tfv.fit(list(train_desc))\n",
    "X =  tfv.transform(train_desc)\n",
    "X_test = tfv.transform(test_desc)\n",
    "print(\"X (tfidf):\", X.shape)\n",
    "\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "svd.fit(X)\n",
    "# print(svd.explained_variance_ratio_.sum())\n",
    "# print(svd.explained_variance_ratio_)\n",
    "X = svd.transform(X)\n",
    "print(\"X (svd):\", X.shape)\n",
    "\n",
    "X = pd.DataFrame(X, columns=['svd_{}'.format(i) for i in range(200)])\n",
    "train = pd.concat((train, X), axis=1)\n",
    "X_test = svd.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=['svd_{}'.format(i) for i in range(200)])\n",
    "test = pd.concat((test, X_test), axis=1)\n",
    "\n",
    "print(\"train:\", train.shape)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading metadata train\n",
      "370\n",
      "2\n",
      "loading metadata test\n",
      "137\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "vertex_xs = []\n",
    "vertex_ys = []\n",
    "bounding_confidences = []\n",
    "bounding_importance_fracs = []\n",
    "dominant_blues = []\n",
    "dominant_greens = []\n",
    "dominant_reds = []\n",
    "dominant_pixel_fracs = []\n",
    "dominant_scores = []\n",
    "label_descriptions = []\n",
    "label_scores = []\n",
    "nf_count = 0\n",
    "nl_count = 0\n",
    "print(\"loading metadata train\")\n",
    "for petid in train_id:\n",
    "    try:\n",
    "        with open('input/train/train_metadata/' + petid + '-1.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n",
    "            vertex_xs.append(vertex_x)\n",
    "            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n",
    "            vertex_ys.append(vertex_y)\n",
    "            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n",
    "            bounding_confidences.append(bounding_confidence)\n",
    "            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n",
    "            bounding_importance_fracs.append(bounding_importance_frac)\n",
    "            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n",
    "            dominant_blues.append(dominant_blue)\n",
    "            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n",
    "            dominant_greens.append(dominant_green)\n",
    "            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n",
    "            dominant_reds.append(dominant_red)\n",
    "            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n",
    "            dominant_pixel_fracs.append(dominant_pixel_frac)\n",
    "            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n",
    "            dominant_scores.append(dominant_score)\n",
    "            if data.get('labelAnnotations'):\n",
    "                label_description = data['labelAnnotations'][0]['description']\n",
    "                label_descriptions.append(label_description)\n",
    "                label_score = data['labelAnnotations'][0]['score']\n",
    "                label_scores.append(label_score)\n",
    "            else:\n",
    "                nl_count += 1\n",
    "                label_descriptions.append('nothing')\n",
    "                label_scores.append(-1)\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        vertex_xs.append(-1)\n",
    "        vertex_ys.append(-1)\n",
    "        bounding_confidences.append(-1)\n",
    "        bounding_importance_fracs.append(-1)\n",
    "        dominant_blues.append(-1)\n",
    "        dominant_greens.append(-1)\n",
    "        dominant_reds.append(-1)\n",
    "        dominant_pixel_fracs.append(-1)\n",
    "        dominant_scores.append(-1)\n",
    "        label_descriptions.append('nothing')\n",
    "        label_scores.append(-1)\n",
    "        pass\n",
    "\n",
    "print(nf_count)\n",
    "print(nl_count)\n",
    "train.loc[:, 'vertex_x'] = vertex_xs\n",
    "train.loc[:, 'vertex_y'] = vertex_ys\n",
    "train.loc[:, 'bounding_confidence'] = bounding_confidences\n",
    "train.loc[:, 'bounding_importance'] = bounding_importance_fracs\n",
    "train.loc[:, 'dominant_blue'] = dominant_blues\n",
    "train.loc[:, 'dominant_green'] = dominant_greens\n",
    "train.loc[:, 'dominant_red'] = dominant_reds\n",
    "train.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n",
    "train.loc[:, 'dominant_score'] = dominant_scores\n",
    "train.loc[:, 'label_description'] = label_descriptions\n",
    "train.loc[:, 'label_score'] = label_scores\n",
    "\n",
    "\n",
    "vertex_xs = []\n",
    "vertex_ys = []\n",
    "bounding_confidences = []\n",
    "bounding_importance_fracs = []\n",
    "dominant_blues = []\n",
    "dominant_greens = []\n",
    "dominant_reds = []\n",
    "dominant_pixel_fracs = []\n",
    "dominant_scores = []\n",
    "label_descriptions = []\n",
    "label_scores = []\n",
    "nf_count = 0\n",
    "nl_count = 0\n",
    "print(\"loading metadata test\")\n",
    "for petid in test_id:\n",
    "    try:\n",
    "        with open('input/test/test_metadata/' + petid + '-1.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n",
    "            vertex_xs.append(vertex_x)\n",
    "            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n",
    "            vertex_ys.append(vertex_y)\n",
    "            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n",
    "            bounding_confidences.append(bounding_confidence)\n",
    "            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n",
    "            bounding_importance_fracs.append(bounding_importance_frac)\n",
    "            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n",
    "            dominant_blues.append(dominant_blue)\n",
    "            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n",
    "            dominant_greens.append(dominant_green)\n",
    "            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n",
    "            dominant_reds.append(dominant_red)\n",
    "            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n",
    "            dominant_pixel_fracs.append(dominant_pixel_frac)\n",
    "            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n",
    "            dominant_scores.append(dominant_score)\n",
    "            if data.get('labelAnnotations'):\n",
    "                label_description = data['labelAnnotations'][0]['description']\n",
    "                label_descriptions.append(label_description)\n",
    "                label_score = data['labelAnnotations'][0]['score']\n",
    "                label_scores.append(label_score)\n",
    "            else:\n",
    "                nl_count += 1\n",
    "                label_descriptions.append('nothing')\n",
    "                label_scores.append(-1)\n",
    "    except Exception:\n",
    "        nf_count += 1\n",
    "        vertex_xs.append(-1)\n",
    "        vertex_ys.append(-1)\n",
    "        bounding_confidences.append(-1)\n",
    "        bounding_importance_fracs.append(-1)\n",
    "        dominant_blues.append(-1)\n",
    "        dominant_greens.append(-1)\n",
    "        dominant_reds.append(-1)\n",
    "        dominant_pixel_fracs.append(-1)\n",
    "        dominant_scores.append(-1)\n",
    "        label_descriptions.append('nothing')\n",
    "        label_scores.append(-1)\n",
    "        pass\n",
    "\n",
    "print(nf_count)\n",
    "test.loc[:, 'vertex_x'] = vertex_xs\n",
    "test.loc[:, 'vertex_y'] = vertex_ys\n",
    "test.loc[:, 'bounding_confidence'] = bounding_confidences\n",
    "test.loc[:, 'bounding_importance'] = bounding_importance_fracs\n",
    "test.loc[:, 'dominant_blue'] = dominant_blues\n",
    "test.loc[:, 'dominant_green'] = dominant_greens\n",
    "test.loc[:, 'dominant_red'] = dominant_reds\n",
    "test.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n",
    "test.loc[:, 'dominant_score'] = dominant_scores\n",
    "test.loc[:, 'label_description'] = label_descriptions\n",
    "test.loc[:, 'label_score'] = label_scores\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)\n",
    "test.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)\n",
    "\n",
    "train.drop(['dominant_green', 'doc_sent_score', 'FurLength', 'Vaccinated', \n",
    "               'Color3', 'Dewormed', 'Health', 'VideoAmt', 'Type',\n",
    "           'bounding_importance', 'bounding_confidence', 'pic_79',\n",
    "           'pic_252', 'pic_109', 'pic_197', 'pic_17', 'pic_104', 'pic_59'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 470)\n",
      "(3948, 488)\n",
      "saved train csv image, metadata, sentiment merged\n",
      "saved test csv image, metadata, sentiment merged\n",
      "getting categorical features\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', \n",
    "                'doc_sent_mag', 'doc_sent_score', 'dominant_score', 'dominant_pixel_frac', \n",
    "                'dominant_red', 'dominant_green', 'dominant_blue', 'bounding_importance', \n",
    "                'bounding_confidence', 'vertex_x', 'vertex_y', 'label_score'] +\\\n",
    "               [col for col in train.columns if col.startswith('pic') or col.startswith('svd')]\n",
    "cat_cols = list(set(train.columns) - set(numeric_cols))\n",
    "train.loc[:, cat_cols] = train[cat_cols].astype('category')\n",
    "test.loc[:, cat_cols] = test[cat_cols].astype('category')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "#print(test.head())\n",
    "drop = \"_drop100\"\n",
    "train.to_csv(r'csv_out/train_ims_merged' + drop + '.csv')\n",
    "print(\"saved train csv image, metadata, sentiment merged\")\n",
    "test.to_csv(r'csv_out/test_ims_merged' + drop +'.csv')\n",
    "print(\"saved test csv image, metadata, sentiment merged\")\n",
    "print(\"getting categorical features\")\n",
    "# get the categorical features\n",
    "foo = train.dtypes\n",
    "cat_feature_names = foo[foo == \"category\"]\n",
    "cat_features = [train.columns.get_loc(c) for c in train.columns if c in cat_feature_names]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run LightGBM Train Model\n",
      "Started lgb fold 1/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10, 468]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03286\tvalid_1's rmse: 1.09873\n",
      "[200]\ttraining's rmse: 0.955043\tvalid_1's rmse: 1.07468\n",
      "[300]\ttraining's rmse: 0.903807\tvalid_1's rmse: 1.06484\n",
      "[400]\ttraining's rmse: 0.861022\tvalid_1's rmse: 1.05864\n",
      "[500]\ttraining's rmse: 0.823981\tvalid_1's rmse: 1.05426\n",
      "[600]\ttraining's rmse: 0.789444\tvalid_1's rmse: 1.0515\n",
      "[700]\ttraining's rmse: 0.75966\tvalid_1's rmse: 1.04855\n",
      "[800]\ttraining's rmse: 0.733438\tvalid_1's rmse: 1.04665\n",
      "[900]\ttraining's rmse: 0.70771\tvalid_1's rmse: 1.04505\n",
      "[1000]\ttraining's rmse: 0.683903\tvalid_1's rmse: 1.04393\n",
      "[1100]\ttraining's rmse: 0.661208\tvalid_1's rmse: 1.04279\n",
      "[1200]\ttraining's rmse: 0.639539\tvalid_1's rmse: 1.04231\n",
      "[1300]\ttraining's rmse: 0.620399\tvalid_1's rmse: 1.04157\n",
      "[1400]\ttraining's rmse: 0.601132\tvalid_1's rmse: 1.04113\n",
      "[1500]\ttraining's rmse: 0.581469\tvalid_1's rmse: 1.04053\n",
      "[1600]\ttraining's rmse: 0.563744\tvalid_1's rmse: 1.04\n",
      "[1700]\ttraining's rmse: 0.544759\tvalid_1's rmse: 1.03946\n",
      "[1800]\ttraining's rmse: 0.528852\tvalid_1's rmse: 1.03911\n",
      "[1900]\ttraining's rmse: 0.513122\tvalid_1's rmse: 1.03891\n",
      "[2000]\ttraining's rmse: 0.496516\tvalid_1's rmse: 1.03882\n",
      "[2100]\ttraining's rmse: 0.481162\tvalid_1's rmse: 1.03842\n",
      "[2200]\ttraining's rmse: 0.467157\tvalid_1's rmse: 1.03827\n",
      "[2300]\ttraining's rmse: 0.453159\tvalid_1's rmse: 1.03778\n",
      "[2400]\ttraining's rmse: 0.43942\tvalid_1's rmse: 1.0376\n",
      "[2500]\ttraining's rmse: 0.426145\tvalid_1's rmse: 1.03739\n",
      "[2600]\ttraining's rmse: 0.413015\tvalid_1's rmse: 1.03734\n",
      "[2700]\ttraining's rmse: 0.400036\tvalid_1's rmse: 1.03694\n",
      "[2800]\ttraining's rmse: 0.388509\tvalid_1's rmse: 1.03689\n",
      "[2900]\ttraining's rmse: 0.376631\tvalid_1's rmse: 1.03691\n",
      "[3000]\ttraining's rmse: 0.365881\tvalid_1's rmse: 1.03681\n",
      "[3100]\ttraining's rmse: 0.35467\tvalid_1's rmse: 1.03672\n",
      "[3200]\ttraining's rmse: 0.343838\tvalid_1's rmse: 1.03689\n",
      "[3300]\ttraining's rmse: 0.333615\tvalid_1's rmse: 1.03678\n",
      "[3400]\ttraining's rmse: 0.324298\tvalid_1's rmse: 1.03698\n",
      "[3500]\ttraining's rmse: 0.315973\tvalid_1's rmse: 1.03688\n",
      "[3600]\ttraining's rmse: 0.306681\tvalid_1's rmse: 1.03705\n",
      "[3700]\ttraining's rmse: 0.297929\tvalid_1's rmse: 1.0371\n",
      "Early stopping, best iteration is:\n",
      "[3102]\ttraining's rmse: 0.354431\tvalid_1's rmse: 1.03669\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted Counts =  Counter({2.0: 1424, 4.0: 751, 3.0: 639, 1.0: 186})\n",
      "Coefficients =  [0.52263981 1.70742783 2.56472335 2.92930404]\n",
      "QWK =  0.44006305263417156\n",
      "Predict 2/2\n",
      "lgb cv score 1: RMSE 1.0366925516815066 QWK 0.44006305263417156\n",
      "Started lgb fold 2/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10, 468]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03495\tvalid_1's rmse: 1.09145\n",
      "[200]\ttraining's rmse: 0.956729\tvalid_1's rmse: 1.06452\n",
      "[300]\ttraining's rmse: 0.902591\tvalid_1's rmse: 1.0536\n",
      "[400]\ttraining's rmse: 0.858616\tvalid_1's rmse: 1.0466\n",
      "[500]\ttraining's rmse: 0.822511\tvalid_1's rmse: 1.04222\n",
      "[600]\ttraining's rmse: 0.793378\tvalid_1's rmse: 1.03923\n",
      "[700]\ttraining's rmse: 0.764942\tvalid_1's rmse: 1.03683\n",
      "[800]\ttraining's rmse: 0.739484\tvalid_1's rmse: 1.03511\n",
      "[900]\ttraining's rmse: 0.714537\tvalid_1's rmse: 1.03389\n",
      "[1000]\ttraining's rmse: 0.689937\tvalid_1's rmse: 1.03294\n",
      "[1100]\ttraining's rmse: 0.666772\tvalid_1's rmse: 1.03214\n",
      "[1200]\ttraining's rmse: 0.644776\tvalid_1's rmse: 1.03145\n",
      "[1300]\ttraining's rmse: 0.624523\tvalid_1's rmse: 1.031\n",
      "[1400]\ttraining's rmse: 0.603369\tvalid_1's rmse: 1.03076\n",
      "[1500]\ttraining's rmse: 0.583592\tvalid_1's rmse: 1.03059\n",
      "[1600]\ttraining's rmse: 0.563707\tvalid_1's rmse: 1.02998\n",
      "[1700]\ttraining's rmse: 0.544721\tvalid_1's rmse: 1.02976\n",
      "[1800]\ttraining's rmse: 0.527983\tvalid_1's rmse: 1.02933\n",
      "[1900]\ttraining's rmse: 0.510281\tvalid_1's rmse: 1.02947\n",
      "[2000]\ttraining's rmse: 0.494342\tvalid_1's rmse: 1.0294\n",
      "[2100]\ttraining's rmse: 0.479857\tvalid_1's rmse: 1.0294\n",
      "[2200]\ttraining's rmse: 0.464767\tvalid_1's rmse: 1.02955\n",
      "[2300]\ttraining's rmse: 0.449181\tvalid_1's rmse: 1.02936\n",
      "[2400]\ttraining's rmse: 0.435107\tvalid_1's rmse: 1.02927\n",
      "[2500]\ttraining's rmse: 0.422132\tvalid_1's rmse: 1.02918\n",
      "[2600]\ttraining's rmse: 0.409317\tvalid_1's rmse: 1.02911\n",
      "[2700]\ttraining's rmse: 0.397162\tvalid_1's rmse: 1.02918\n",
      "[2800]\ttraining's rmse: 0.385973\tvalid_1's rmse: 1.02901\n",
      "[2900]\ttraining's rmse: 0.375063\tvalid_1's rmse: 1.02908\n",
      "[3000]\ttraining's rmse: 0.364051\tvalid_1's rmse: 1.02928\n",
      "[3100]\ttraining's rmse: 0.353201\tvalid_1's rmse: 1.02938\n",
      "Early stopping, best iteration is:\n",
      "[2535]\ttraining's rmse: 0.417738\tvalid_1's rmse: 1.02898\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted Counts =  Counter({3.0: 939, 1.0: 766, 2.0: 662, 4.0: 633})\n",
      "Coefficients =  [0.4909152  2.12126702 2.45600678 3.00376341]\n",
      "QWK =  0.4752228194827043\n",
      "Predict 2/2\n",
      "lgb cv score 2: RMSE 1.0289788742536652 QWK 0.4752228194827043\n",
      "Started lgb fold 3/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10, 468]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03566\tvalid_1's rmse: 1.08982\n",
      "[200]\ttraining's rmse: 0.958113\tvalid_1's rmse: 1.06248\n",
      "[300]\ttraining's rmse: 0.904145\tvalid_1's rmse: 1.04977\n",
      "[400]\ttraining's rmse: 0.863175\tvalid_1's rmse: 1.04221\n",
      "[500]\ttraining's rmse: 0.826946\tvalid_1's rmse: 1.03705\n",
      "[600]\ttraining's rmse: 0.793412\tvalid_1's rmse: 1.03361\n",
      "[700]\ttraining's rmse: 0.763222\tvalid_1's rmse: 1.03064\n",
      "[800]\ttraining's rmse: 0.734324\tvalid_1's rmse: 1.02827\n",
      "[900]\ttraining's rmse: 0.710221\tvalid_1's rmse: 1.02675\n",
      "[1000]\ttraining's rmse: 0.685177\tvalid_1's rmse: 1.02545\n",
      "[1100]\ttraining's rmse: 0.661229\tvalid_1's rmse: 1.02475\n",
      "[1200]\ttraining's rmse: 0.638601\tvalid_1's rmse: 1.02418\n",
      "[1300]\ttraining's rmse: 0.617182\tvalid_1's rmse: 1.02386\n",
      "[1400]\ttraining's rmse: 0.596695\tvalid_1's rmse: 1.02333\n",
      "[1500]\ttraining's rmse: 0.578004\tvalid_1's rmse: 1.02311\n",
      "[1600]\ttraining's rmse: 0.560371\tvalid_1's rmse: 1.02309\n",
      "[1700]\ttraining's rmse: 0.541886\tvalid_1's rmse: 1.02292\n",
      "[1800]\ttraining's rmse: 0.524019\tvalid_1's rmse: 1.02281\n",
      "[1900]\ttraining's rmse: 0.508844\tvalid_1's rmse: 1.0226\n",
      "[2000]\ttraining's rmse: 0.493536\tvalid_1's rmse: 1.02223\n",
      "[2100]\ttraining's rmse: 0.479176\tvalid_1's rmse: 1.02191\n",
      "[2200]\ttraining's rmse: 0.464529\tvalid_1's rmse: 1.02171\n",
      "[2300]\ttraining's rmse: 0.450797\tvalid_1's rmse: 1.02138\n",
      "[2400]\ttraining's rmse: 0.436924\tvalid_1's rmse: 1.02135\n",
      "[2500]\ttraining's rmse: 0.42455\tvalid_1's rmse: 1.02115\n",
      "[2600]\ttraining's rmse: 0.411218\tvalid_1's rmse: 1.02105\n",
      "[2700]\ttraining's rmse: 0.398831\tvalid_1's rmse: 1.02092\n",
      "[2800]\ttraining's rmse: 0.387972\tvalid_1's rmse: 1.02072\n",
      "[2900]\ttraining's rmse: 0.377163\tvalid_1's rmse: 1.02065\n",
      "[3000]\ttraining's rmse: 0.365762\tvalid_1's rmse: 1.02071\n",
      "[3100]\ttraining's rmse: 0.354859\tvalid_1's rmse: 1.02086\n",
      "[3200]\ttraining's rmse: 0.344227\tvalid_1's rmse: 1.02087\n",
      "[3300]\ttraining's rmse: 0.334242\tvalid_1's rmse: 1.02081\n",
      "[3400]\ttraining's rmse: 0.325832\tvalid_1's rmse: 1.02071\n",
      "[3500]\ttraining's rmse: 0.316674\tvalid_1's rmse: 1.02075\n",
      "[3600]\ttraining's rmse: 0.307518\tvalid_1's rmse: 1.0207\n",
      "[3700]\ttraining's rmse: 0.298911\tvalid_1's rmse: 1.02063\n",
      "[3800]\ttraining's rmse: 0.290941\tvalid_1's rmse: 1.02069\n",
      "[3900]\ttraining's rmse: 0.282883\tvalid_1's rmse: 1.02072\n",
      "[4000]\ttraining's rmse: 0.274473\tvalid_1's rmse: 1.02091\n",
      "[4100]\ttraining's rmse: 0.266532\tvalid_1's rmse: 1.02084\n",
      "[4200]\ttraining's rmse: 0.258719\tvalid_1's rmse: 1.02091\n",
      "Early stopping, best iteration is:\n",
      "[3693]\ttraining's rmse: 0.299522\tvalid_1's rmse: 1.02057\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted Counts =  Counter({3.0: 857, 1.0: 792, 2.0: 706, 4.0: 642, 0.0: 1})\n",
      "Coefficients =  [0.49396493 2.12679965 2.48592725 2.99993516]\n",
      "QWK =  0.47674506599964395\n",
      "Predict 2/2\n",
      "lgb cv score 3: RMSE 1.0205742680495442 QWK 0.47674506599964395\n",
      "Started lgb fold 4/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10, 468]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03626\tvalid_1's rmse: 1.09318\n",
      "[200]\ttraining's rmse: 0.958158\tvalid_1's rmse: 1.0648\n",
      "[300]\ttraining's rmse: 0.903699\tvalid_1's rmse: 1.05246\n",
      "[400]\ttraining's rmse: 0.861604\tvalid_1's rmse: 1.04644\n",
      "[500]\ttraining's rmse: 0.82393\tvalid_1's rmse: 1.04213\n",
      "[600]\ttraining's rmse: 0.7906\tvalid_1's rmse: 1.03846\n",
      "[700]\ttraining's rmse: 0.760295\tvalid_1's rmse: 1.03671\n",
      "[800]\ttraining's rmse: 0.732531\tvalid_1's rmse: 1.03508\n",
      "[900]\ttraining's rmse: 0.705178\tvalid_1's rmse: 1.03415\n",
      "[1000]\ttraining's rmse: 0.681793\tvalid_1's rmse: 1.03368\n",
      "[1100]\ttraining's rmse: 0.659112\tvalid_1's rmse: 1.03304\n",
      "[1200]\ttraining's rmse: 0.636603\tvalid_1's rmse: 1.03269\n",
      "[1300]\ttraining's rmse: 0.615344\tvalid_1's rmse: 1.0324\n",
      "[1400]\ttraining's rmse: 0.597488\tvalid_1's rmse: 1.0326\n",
      "[1500]\ttraining's rmse: 0.577913\tvalid_1's rmse: 1.03257\n",
      "[1600]\ttraining's rmse: 0.559492\tvalid_1's rmse: 1.03242\n",
      "[1700]\ttraining's rmse: 0.543076\tvalid_1's rmse: 1.03256\n",
      "[1800]\ttraining's rmse: 0.526548\tvalid_1's rmse: 1.03265\n",
      "[1900]\ttraining's rmse: 0.510046\tvalid_1's rmse: 1.03293\n",
      "Early stopping, best iteration is:\n",
      "[1312]\ttraining's rmse: 0.612932\tvalid_1's rmse: 1.03236\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted Counts =  Counter({2.0: 1193, 4.0: 751, 3.0: 656, 1.0: 398})\n",
      "Coefficients =  [0.49778012 1.90366537 2.50384421 2.89480971]\n",
      "QWK =  0.45597091680028423\n",
      "Predict 2/2\n",
      "lgb cv score 4: RMSE 1.0323597046769437 QWK 0.45597091680028423\n",
      "Started lgb fold 5/5\n",
      "Prep LGB\n",
      "Train LGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1188: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [1, 2, 3, 4, 5, 6, 7, 10, 468]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "C:\\Users\\Sunfl\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.03512\tvalid_1's rmse: 1.09475\n",
      "[200]\ttraining's rmse: 0.956667\tvalid_1's rmse: 1.06621\n",
      "[300]\ttraining's rmse: 0.90111\tvalid_1's rmse: 1.05368\n",
      "[400]\ttraining's rmse: 0.855444\tvalid_1's rmse: 1.04577\n",
      "[500]\ttraining's rmse: 0.816423\tvalid_1's rmse: 1.04166\n",
      "[600]\ttraining's rmse: 0.782636\tvalid_1's rmse: 1.03861\n",
      "[700]\ttraining's rmse: 0.75324\tvalid_1's rmse: 1.0366\n",
      "[800]\ttraining's rmse: 0.725484\tvalid_1's rmse: 1.0348\n",
      "[900]\ttraining's rmse: 0.700621\tvalid_1's rmse: 1.0332\n",
      "[1000]\ttraining's rmse: 0.677416\tvalid_1's rmse: 1.03222\n",
      "[1100]\ttraining's rmse: 0.654773\tvalid_1's rmse: 1.03168\n",
      "[1200]\ttraining's rmse: 0.633067\tvalid_1's rmse: 1.0311\n",
      "[1300]\ttraining's rmse: 0.612844\tvalid_1's rmse: 1.03068\n",
      "[1400]\ttraining's rmse: 0.59392\tvalid_1's rmse: 1.0301\n",
      "[1500]\ttraining's rmse: 0.574021\tvalid_1's rmse: 1.03001\n",
      "[1600]\ttraining's rmse: 0.557851\tvalid_1's rmse: 1.02972\n",
      "[1700]\ttraining's rmse: 0.542437\tvalid_1's rmse: 1.02973\n",
      "[1800]\ttraining's rmse: 0.525176\tvalid_1's rmse: 1.02951\n",
      "[1900]\ttraining's rmse: 0.51\tvalid_1's rmse: 1.02956\n",
      "[2000]\ttraining's rmse: 0.495175\tvalid_1's rmse: 1.0297\n",
      "[2100]\ttraining's rmse: 0.481212\tvalid_1's rmse: 1.02947\n",
      "[2200]\ttraining's rmse: 0.466473\tvalid_1's rmse: 1.02923\n",
      "[2300]\ttraining's rmse: 0.453007\tvalid_1's rmse: 1.02933\n",
      "[2400]\ttraining's rmse: 0.439811\tvalid_1's rmse: 1.02909\n",
      "[2500]\ttraining's rmse: 0.426935\tvalid_1's rmse: 1.02904\n",
      "[2600]\ttraining's rmse: 0.413517\tvalid_1's rmse: 1.02879\n",
      "[2700]\ttraining's rmse: 0.401282\tvalid_1's rmse: 1.02902\n",
      "[2800]\ttraining's rmse: 0.390147\tvalid_1's rmse: 1.02908\n",
      "[2900]\ttraining's rmse: 0.377863\tvalid_1's rmse: 1.02901\n",
      "[3000]\ttraining's rmse: 0.367018\tvalid_1's rmse: 1.02897\n",
      "[3100]\ttraining's rmse: 0.35661\tvalid_1's rmse: 1.02906\n",
      "[3200]\ttraining's rmse: 0.345406\tvalid_1's rmse: 1.02916\n",
      "Early stopping, best iteration is:\n",
      "[2605]\ttraining's rmse: 0.412744\tvalid_1's rmse: 1.02876\n",
      "Predict 1/2\n",
      "Valid Counts =  Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted Counts =  Counter({2.0: 1412, 4.0: 833, 3.0: 534, 1.0: 218})\n",
      "Coefficients =  [0.50457918 1.74414279 2.52079249 2.8323859 ]\n",
      "QWK =  0.4442736803489913\n",
      "Predict 2/2\n",
      "lgb cv score 5: RMSE 1.0287597410895686 QWK 0.4442736803489913\n",
      "lgb cv RMSE scores : [1.0366925516815066, 1.0289788742536652, 1.0205742680495442, 1.0323597046769437, 1.0287597410895686]\n",
      "lgb cv mean RMSE score : 1.0294730279502455\n",
      "lgb cv std RMSE score : 1.0294730279502455\n",
      "lgb cv QWK scores : [0.44006305263417156, 0.4752228194827043, 0.47674506599964395, 0.45597091680028423, 0.4442736803489913]\n",
      "lgb cv mean QWK score : 0.45845510705315906\n",
      "lgb cv std QWK score : 0.01523962275591615\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 5\n",
    "def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, random_state=42, shuffle=True)\n",
    "    fold_splits = kf.split(train, target)\n",
    "    cv_scores = []\n",
    "    qwk_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros((train.shape[0], N_SPLITS))\n",
    "    all_coefficients = np.zeros((N_SPLITS, 4))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    i = 1\n",
    "    for dev_index, val_index in fold_splits:\n",
    "        print('Started ' + label + ' fold ' + str(i) + '/' + str(N_SPLITS))\n",
    "        if isinstance(train, pd.DataFrame):\n",
    "            dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        else:\n",
    "            dev_X, val_X = train[dev_index], train[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        params2 = params.copy()\n",
    "        pred_val_y, pred_test_y, importances, coefficients, qwk = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index] = pred_val_y\n",
    "        all_coefficients[i-1, :] = coefficients\n",
    "        if eval_fn is not None:\n",
    "            cv_score = eval_fn(val_y, pred_val_y)\n",
    "            cv_scores.append(cv_score)\n",
    "            qwk_scores.append(qwk)\n",
    "            print(label + ' cv score {}: RMSE {} QWK {}'.format(i, cv_score, qwk))\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = train.columns.values\n",
    "        fold_importance_df['importance'] = importances\n",
    "        fold_importance_df['fold'] = i\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)        \n",
    "        i += 1\n",
    "    print('{} cv RMSE scores : {}'.format(label, cv_scores))\n",
    "    print('{} cv mean RMSE score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv std RMSE score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv QWK scores : {}'.format(label, qwk_scores))\n",
    "    print('{} cv mean QWK score : {}'.format(label, np.mean(qwk_scores)))\n",
    "    print('{} cv std QWK score : {}'.format(label, np.std(qwk_scores)))\n",
    "    pred_full_test = pred_full_test / float(N_SPLITS)\n",
    "    results = {'label': label,\n",
    "               'train': pred_train, 'test': pred_full_test,\n",
    "                'cv': cv_scores, 'qwk': qwk_scores,\n",
    "               'importance': feature_importance_df,\n",
    "               'coefficients': all_coefficients}\n",
    "    return results\n",
    "\n",
    "params = {'application': 'regression',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves': 70,\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.85,\n",
    "          'feature_fraction': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'min_child_samples': 150,\n",
    "          'min_child_weight': 0.02,\n",
    "          'lambda_l2': 0.0475,\n",
    "          'verbosity': -1,\n",
    "          'data_random_seed': 17,\n",
    "          'early_stop': 600,\n",
    "          'verbose_eval': 100,\n",
    "          'num_rounds': 10000}\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y, test_X2, params):\n",
    "    print('Prep LGB')\n",
    "    d_train = lgb.Dataset(train_X, label=train_y)\n",
    "    d_valid = lgb.Dataset(test_X, label=test_y)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    print('Train LGB')\n",
    "    num_rounds = params.pop('num_rounds')\n",
    "    verbose_eval = params.pop('verbose_eval')\n",
    "    early_stop = None\n",
    "    if params.get('early_stop'):\n",
    "        early_stop = params.pop('early_stop')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                      categorical_feature=list(cat_features),\n",
    "                      early_stopping_rounds=early_stop)\n",
    "    \n",
    "    print('Predict 1/2')\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(pred_test_y, test_y)\n",
    "    coefficients = optR.coefficients()\n",
    "    pred_test_y_k = optR.predict(pred_test_y, coefficients)\n",
    "    print(\"Valid Counts = \", Counter(test_y))\n",
    "    print(\"Predicted Counts = \", Counter(pred_test_y_k))\n",
    "    print(\"Coefficients = \", coefficients)\n",
    "    qwk = quadratic_weighted_kappa(test_y, pred_test_y_k)\n",
    "    print(\"QWK = \", qwk)\n",
    "    print('Predict 2/2')\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "    return pred_test_y.reshape(-1, 1), pred_test_y2.reshape(-1, 1), model.feature_importance(), coefficients, qwk\n",
    "\n",
    "print(\"Run LightGBM Train Model\")\n",
    "results = run_cv_model(train, test, target, runLGB, params, rmse, 'lgb')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breed1</td>\n",
       "      <td>1655.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>739.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breed2</td>\n",
       "      <td>493.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>State</td>\n",
       "      <td>443.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>label_score</td>\n",
       "      <td>366.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>svd_184</td>\n",
       "      <td>353.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>svd_47</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>svd_166</td>\n",
       "      <td>350.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quantity</td>\n",
       "      <td>346.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>svd_70</td>\n",
       "      <td>339.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>vertex_y</td>\n",
       "      <td>333.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>pic_224</td>\n",
       "      <td>330.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>svd_52</td>\n",
       "      <td>327.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>pic_189</td>\n",
       "      <td>321.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>svd_199</td>\n",
       "      <td>318.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>svd_45</td>\n",
       "      <td>310.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>svd_111</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>svd_30</td>\n",
       "      <td>301.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pic_145</td>\n",
       "      <td>299.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>svd_123</td>\n",
       "      <td>294.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>svd_75</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>pic_49</td>\n",
       "      <td>292.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doc_sent_mag</td>\n",
       "      <td>289.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>svd_153</td>\n",
       "      <td>288.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>svd_0</td>\n",
       "      <td>288.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>pic_160</td>\n",
       "      <td>287.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>svd_163</td>\n",
       "      <td>285.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pic_132</td>\n",
       "      <td>280.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>svd_119</td>\n",
       "      <td>278.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>svd_137</td>\n",
       "      <td>276.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>pic_152</td>\n",
       "      <td>134.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pic_118</td>\n",
       "      <td>134.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>pic_170</td>\n",
       "      <td>133.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>pic_159</td>\n",
       "      <td>133.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pic_125</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pic_210</td>\n",
       "      <td>131.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>pic_53</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pic_222</td>\n",
       "      <td>129.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pic_134</td>\n",
       "      <td>129.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>pic_95</td>\n",
       "      <td>128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pic_140</td>\n",
       "      <td>128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>pic_50</td>\n",
       "      <td>128.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pic_165</td>\n",
       "      <td>125.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>pic_98</td>\n",
       "      <td>125.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>pic_71</td>\n",
       "      <td>125.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pic_10</td>\n",
       "      <td>124.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dominant_red</td>\n",
       "      <td>123.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>pic_43</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>pic_62</td>\n",
       "      <td>122.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pic_100</td>\n",
       "      <td>122.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pic_143</td>\n",
       "      <td>122.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>pic_82</td>\n",
       "      <td>122.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pic_34</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MaturitySize</td>\n",
       "      <td>121.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pic_215</td>\n",
       "      <td>120.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>pic_93</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>pic_38</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>pic_26</td>\n",
       "      <td>112.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>pic_5</td>\n",
       "      <td>100.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>label_description</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "1               Breed1      1655.4\n",
       "0                  Age       739.2\n",
       "2               Breed2       493.8\n",
       "10               State       443.6\n",
       "18         label_score       366.2\n",
       "363            svd_184       353.2\n",
       "410             svd_47       353.0\n",
       "343            svd_166       350.2\n",
       "9             Quantity       346.2\n",
       "436             svd_70       339.2\n",
       "469           vertex_y       333.2\n",
       "155            pic_224       330.2\n",
       "416             svd_52       327.6\n",
       "116            pic_189       321.8\n",
       "379            svd_199       318.4\n",
       "408             svd_45       310.6\n",
       "283            svd_111       302.0\n",
       "392             svd_30       301.4\n",
       "69             pic_145       299.2\n",
       "296            svd_123       294.8\n",
       "441             svd_75       293.0\n",
       "214             pic_49       292.4\n",
       "12        doc_sent_mag       289.6\n",
       "329            svd_153       288.4\n",
       "268              svd_0       288.4\n",
       "86             pic_160       287.2\n",
       "340            svd_163       285.2\n",
       "55             pic_132       280.8\n",
       "291            svd_119       278.4\n",
       "311            svd_137       276.6\n",
       "..                 ...         ...\n",
       "77             pic_152       134.4\n",
       "39             pic_118       134.4\n",
       "96             pic_170       133.6\n",
       "84             pic_159       133.6\n",
       "47             pic_125       133.0\n",
       "140            pic_210       131.4\n",
       "219             pic_53       130.0\n",
       "153            pic_222       129.4\n",
       "57             pic_134       129.2\n",
       "263             pic_95       128.8\n",
       "64             pic_140       128.8\n",
       "216             pic_50       128.6\n",
       "91             pic_165       125.8\n",
       "266             pic_98       125.4\n",
       "238             pic_71       125.4\n",
       "21              pic_10       124.2\n",
       "15        dominant_red       123.2\n",
       "208             pic_43       123.0\n",
       "228             pic_62       122.8\n",
       "22             pic_100       122.6\n",
       "67             pic_143       122.2\n",
       "249             pic_82       122.2\n",
       "198             pic_34       122.0\n",
       "7         MaturitySize       121.4\n",
       "145            pic_215       120.2\n",
       "261             pic_93       118.0\n",
       "202             pic_38       118.0\n",
       "189             pic_26       112.6\n",
       "215              pic_5       100.4\n",
       "17   label_description        42.8\n",
       "\n",
       "[470 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports = results['importance'].groupby('feature')['feature', 'importance'].mean().reset_index()\n",
    "imports.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving out feature importance list to CSV\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"saving out feature importance list to CSV\")\n",
    "imports.to_csv(\"csv_out/features_importance.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50197585 1.92066053 2.50625882 2.93203965]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({3: 2919, 1: 3036, 2: 4012, 4: 4284, 0: 742})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "coefficients_ = np.mean(results['coefficients'], axis=0)\n",
    "print(coefficients_)\n",
    "# manually adjust coefs\n",
    "coefficients_[0] = 1.645\n",
    "coefficients_[1] = 2.115\n",
    "coefficients_[3] = 2.84\n",
    "train_predictions = [r[0] for r in results['train']]\n",
    "train_predictions = optR.predict(train_predictions, coefficients_).astype(int)\n",
    "Counter(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50197585 1.92066053 2.50625882 2.93203965]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 2163, 3: 1282, 4: 101, 1: 398, 0: 4})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "coefficients_ = np.mean(results['coefficients'], axis=0)\n",
    "print(coefficients_)\n",
    "# manually adjust coefs\n",
    "coefficients_[0] = 1.645\n",
    "coefficients_[1] = 2.115\n",
    "coefficients_[3] = 2.84\n",
    "test_predictions = [r[0] for r in results['test']]\n",
    "test_predictions = optR.predict(test_predictions, coefficients_).astype(int)\n",
    "Counter(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Distribution:\n",
      "0    0.027346\n",
      "1    0.206096\n",
      "2    0.269259\n",
      "3    0.217368\n",
      "4    0.279931\n",
      "Name: AdoptionSpeed, dtype: float64\n",
      "Test Predicted Distribution:\n",
      "0    0.001013\n",
      "1    0.100811\n",
      "2    0.547872\n",
      "3    0.324721\n",
      "4    0.025583\n",
      "dtype: float64\n",
      "Train Predicted Distribution:\n",
      "0    0.049490\n",
      "1    0.202494\n",
      "2    0.267592\n",
      "3    0.194691\n",
      "4    0.285733\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"True Distribution:\")\n",
    "print(pd.value_counts(target, normalize=True).sort_index())\n",
    "print(\"Test Predicted Distribution:\")\n",
    "print(pd.value_counts(test_predictions, normalize=True).sort_index())\n",
    "print(\"Train Predicted Distribution:\")\n",
    "print(pd.value_counts(train_predictions, normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>98</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358</td>\n",
       "      <td>1077</td>\n",
       "      <td>937</td>\n",
       "      <td>441</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>1011</td>\n",
       "      <td>1317</td>\n",
       "      <td>821</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>601</td>\n",
       "      <td>998</td>\n",
       "      <td>758</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>225</td>\n",
       "      <td>662</td>\n",
       "      <td>842</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4\n",
       "0   81   122    98   57    52\n",
       "1  358  1077   937  441   277\n",
       "2  210  1011  1317  821   678\n",
       "3   78   601   998  758   824\n",
       "4   15   225   662  842  2453"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sk_cmatrix(target, train_predictions), index=list(range(5)), columns=list(range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              2\n",
       "1  73c10e136              2\n",
       "2  72000c4c5              2\n",
       "3  e147a4b9f              3\n",
       "4  43fbba852              3"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_weighted_kappa(target, train_predictions)\n",
    "rmse(target, [r[0] for r in results['train']])\n",
    "submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/LightBGM with image features/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
